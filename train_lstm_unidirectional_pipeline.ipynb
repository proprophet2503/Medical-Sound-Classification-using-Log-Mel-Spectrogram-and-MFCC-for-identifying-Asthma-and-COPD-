{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67a791c",
   "metadata": {},
   "source": [
    "# Respiratory Disease Classification using Unidirectional LSTM\n",
    "## Multi-class Classification (Healthy, COPD, Asthma)\n",
    "\n",
    "Pipeline lengkap untuk training model LSTM (non-bidirectional) menggunakan MFCC features dari audio cough dan vowel.\n",
    "\n",
    "**Classes:**\n",
    "- **Class 0: Healthy**\n",
    "- **Class 1: COPD** \n",
    "- **Class 2: Asthma**\n",
    "\n",
    "## Pipeline:\n",
    "1. Load data dari dataclean_cough dan dataclean_vowel\n",
    "2. Extract MFCC features real-time dari audio files\n",
    "3. Split berdasarkan train.csv dan test.csv dengan validation split\n",
    "4. Training SINGLE unified model dengan attention mechanism\n",
    "5. Evaluasi dengan metrics: Accuracy, F1, Recall, Precision, Confusion Matrix\n",
    "6. Prediction pada test set\n",
    "7. Save hasil ke CSV\n",
    "\n",
    "**NOTE:** This version uses standard (unidirectional) LSTM instead of bidirectional LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8024b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc262411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    fbeta_score, confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbfb2a4",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9887b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration (UNIDIRECTIONAL LSTM):\n",
      "  Sample Rate: 16000 Hz\n",
      "  Duration: 2.0 seconds\n",
      "  N_MFCC: 20\n",
      "  Input Features: 60\n",
      "  Hidden Size: 128\n",
      "  Output Classes: 3 (0=Healthy, 1=COPD, 2=Asthma)\n",
      "  Batch Size: 16\n",
      "  Learning Rate: 0.0005\n",
      "  Epochs: 150\n",
      "  Dropout: 0.4\n",
      "  Weight Decay: 0.001\n",
      "  Augmentation: True\n",
      "  Combine Mode: concat\n",
      "  Bidirectional: False *** UNIDIRECTIONAL MODE ***\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    # Paths\n",
    "    BASE_PATH = Path('/mnt/ml_storage/Final_Project/SOURCE2')\n",
    "    COUGH_PATH = BASE_PATH / 'dataclean_cough_1'\n",
    "    VOWEL_PATH = BASE_PATH / 'dataclean_vowel_1'\n",
    "    TRAIN_CSV = BASE_PATH / 'train.csv'\n",
    "    TEST_CSV = BASE_PATH / 'test.csv'\n",
    "    MODEL_DIR = BASE_PATH / 'models'\n",
    "    \n",
    "    # Audio parameters - IMPROVED\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 2.0  # Increased from 1.0 to capture more context\n",
    "    N_FFT = 2048  # Increased for better frequency resolution\n",
    "    HOP_LENGTH = 512  # Adjusted for new N_FFT\n",
    "    WIN_LENGTH = 2048\n",
    "    N_MFCC = 20  # Increased from 13 for richer features\n",
    "    N_MELS = 64  # Increased from 40\n",
    "    \n",
    "    # Model parameters - UNIDIRECTIONAL LSTM\n",
    "    INPUT_SIZE = 60  # 20 MFCC + 20 Delta + 20 Delta-Delta\n",
    "    HIDDEN_SIZE = 128  # Reduced to prevent overfitting\n",
    "    NUM_LAYERS = 2\n",
    "    OUTPUT_SIZE = 3  # 3 classes: Healthy(0), COPD(1), Asthma(2)\n",
    "    DROPOUT = 0.4  # Increased dropout\n",
    "    BIDIRECTIONAL = False  # *** CHANGED: Using unidirectional LSTM ***\n",
    "    \n",
    "    # Training parameters - IMPROVED\n",
    "    BATCH_SIZE = 16  # Smaller batch for better generalization\n",
    "    LEARNING_RATE = 0.0005  # Slightly lower for stability\n",
    "    NUM_EPOCHS = 150\n",
    "    VAL_SPLIT = 0.2\n",
    "    PATIENCE = 25  # More patience\n",
    "    GRADIENT_CLIP = 1.0\n",
    "    WEIGHT_DECAY = 1e-3  # Stronger regularization\n",
    "    \n",
    "    # Data augmentation\n",
    "    USE_AUGMENTATION = True\n",
    "    MIXUP_ALPHA = 0.2  # Mixup augmentation strength\n",
    "    \n",
    "    # Audio combination mode\n",
    "    COMBINE_MODE = \"concat\"  # Options: \"concat\", \"average\", \"cough_only\", \"vowel_only\"\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Create model directory\n",
    "config.MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration (UNIDIRECTIONAL LSTM):\")\n",
    "print(f\"  Sample Rate: {config.SAMPLE_RATE} Hz\")\n",
    "print(f\"  Duration: {config.DURATION} seconds\")\n",
    "print(f\"  N_MFCC: {config.N_MFCC}\")\n",
    "print(f\"  Input Features: {config.INPUT_SIZE}\")\n",
    "print(f\"  Hidden Size: {config.HIDDEN_SIZE}\")\n",
    "print(f\"  Output Classes: {config.OUTPUT_SIZE} (0=Healthy, 1=COPD, 2=Asthma)\")\n",
    "print(f\"  Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {config.LEARNING_RATE}\")\n",
    "print(f\"  Epochs: {config.NUM_EPOCHS}\")\n",
    "print(f\"  Dropout: {config.DROPOUT}\")\n",
    "print(f\"  Weight Decay: {config.WEIGHT_DECAY}\")\n",
    "print(f\"  Augmentation: {config.USE_AUGMENTATION}\")\n",
    "print(f\"  Combine Mode: {config.COMBINE_MODE}\")\n",
    "print(f\"  Bidirectional: {config.BIDIRECTIONAL} *** UNIDIRECTIONAL MODE ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0a76be",
   "metadata": {},
   "source": [
    "## 3. Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcb50e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance handling function defined!\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(labels, method='sqrt'):\n",
    "    \"\"\"\n",
    "    Compute class weights for imbalanced dataset\n",
    "    \n",
    "    Methods:\n",
    "    - 'balanced': weight = total_samples / (num_classes * class_count) \n",
    "    - 'sqrt': weight = sqrt(max_count / class_count) - softer weighting\n",
    "    - 'none': equal weights for all classes\n",
    "    \"\"\"\n",
    "    unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
    "    total_samples = len(labels)\n",
    "    num_classes = len(unique_classes)\n",
    "    \n",
    "    if method == 'balanced':\n",
    "        # Standard sklearn balanced weighting\n",
    "        class_weights = total_samples / (num_classes * class_counts)\n",
    "    elif method == 'sqrt':\n",
    "        # Softer weighting using square root\n",
    "        max_count = class_counts.max()\n",
    "        class_weights = np.sqrt(max_count / class_counts)\n",
    "    else:\n",
    "        # No weighting\n",
    "        class_weights = np.ones(num_classes)\n",
    "    \n",
    "    print(f\"\\nClass Imbalance Analysis (method='{method}'):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{'Class':<15} {'Count':<10} {'Percentage':<15} {'Weight':<10}\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    class_names = ['Healthy', 'COPD', 'Asthma']\n",
    "    for cls, count, weight in zip(unique_classes, class_counts, class_weights):\n",
    "        percentage = count / total_samples * 100\n",
    "        print(f\"{class_names[int(cls)]:<15} {count:<10} {percentage:<15.2f} {weight:<10.4f}\")\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Weight ratio (max/min): {class_weights.max()/class_weights.min():.2f}x\")\n",
    "    \n",
    "    return torch.FloatTensor(class_weights)\n",
    "\n",
    "\n",
    "print(\"Class imbalance handling function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1e660",
   "metadata": {},
   "source": [
    "## 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3025c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class RespiratoryDataset(Dataset):\n",
    "    \"\"\"Unified dataset that combines cough and vowel audio features\"\"\"\n",
    "    \n",
    "    def __init__(self, candidate_ids, labels, config, is_test=False, augment=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            candidate_ids: List of candidate IDs\n",
    "            labels: List of labels (0: Healthy, 1: COPD, 2: Asthma) or None for test\n",
    "            config: Configuration object\n",
    "            is_test: whether this is test set (no labels)\n",
    "            augment: whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.candidate_ids = candidate_ids\n",
    "        self.labels = labels\n",
    "        self.config = config\n",
    "        self.is_test = is_test\n",
    "        self.augment = augment and not is_test  # Only augment training data\n",
    "        self.cough_path = config.COUGH_PATH\n",
    "        self.vowel_path = config.VOWEL_PATH\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.candidate_ids)\n",
    "    \n",
    "    def _augment_audio(self, audio):\n",
    "        \"\"\"Apply random audio augmentations\"\"\"\n",
    "        if not self.augment or np.random.random() > 0.5:\n",
    "            return audio\n",
    "        \n",
    "        # Choose one augmentation randomly\n",
    "        aug_type = np.random.choice(['noise', 'shift', 'speed', 'gain'])\n",
    "        \n",
    "        if aug_type == 'noise':\n",
    "            # Add random noise\n",
    "            noise_factor = np.random.uniform(0.001, 0.005)\n",
    "            noise = np.random.randn(len(audio)) * noise_factor\n",
    "            audio = audio + noise\n",
    "            \n",
    "        elif aug_type == 'shift':\n",
    "            # Time shift\n",
    "            shift_max = int(len(audio) * 0.1)\n",
    "            shift = np.random.randint(-shift_max, shift_max)\n",
    "            audio = np.roll(audio, shift)\n",
    "            \n",
    "        elif aug_type == 'speed':\n",
    "            # Speed perturbation (subtle)\n",
    "            speed_factor = np.random.uniform(0.95, 1.05)\n",
    "            audio = librosa.effects.time_stretch(audio, rate=speed_factor)\n",
    "            # Adjust length back\n",
    "            target_len = int(self.config.SAMPLE_RATE * self.config.DURATION)\n",
    "            if len(audio) > target_len:\n",
    "                audio = audio[:target_len]\n",
    "            else:\n",
    "                audio = np.pad(audio, (0, target_len - len(audio)), mode='constant')\n",
    "                \n",
    "        elif aug_type == 'gain':\n",
    "            # Random gain\n",
    "            gain_factor = np.random.uniform(0.8, 1.2)\n",
    "            audio = audio * gain_factor\n",
    "        \n",
    "        return audio\n",
    "    \n",
    "    def _load_and_extract_features(self, audio_path):\n",
    "        \"\"\"Load audio and extract MFCC features\"\"\"\n",
    "        try:\n",
    "            audio, sr = librosa.load(audio_path, sr=self.config.SAMPLE_RATE)\n",
    "            \n",
    "            # Segment to target duration\n",
    "            target_samples = int(self.config.SAMPLE_RATE * self.config.DURATION)\n",
    "            if len(audio) > target_samples:\n",
    "                audio = audio[:target_samples]\n",
    "            else:\n",
    "                audio = np.pad(audio, (0, target_samples - len(audio)), mode='constant')\n",
    "            \n",
    "            # Apply augmentation (training only)\n",
    "            if self.augment:\n",
    "                audio = self._augment_audio(audio)\n",
    "            \n",
    "            # Extract MFCC with config parameters\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=audio,\n",
    "                sr=self.config.SAMPLE_RATE,\n",
    "                n_mfcc=self.config.N_MFCC,\n",
    "                n_fft=self.config.N_FFT,\n",
    "                hop_length=self.config.HOP_LENGTH,\n",
    "                n_mels=self.config.N_MELS\n",
    "            )\n",
    "            \n",
    "            # Extract delta and delta-delta\n",
    "            delta = librosa.feature.delta(mfcc)\n",
    "            delta_delta = librosa.feature.delta(mfcc, order=2)\n",
    "            \n",
    "            # Combine features (N_MFCC*3, n_frames)\n",
    "            features = np.vstack([mfcc, delta, delta_delta])\n",
    "            \n",
    "            # Transpose to (n_frames, N_MFCC*3)\n",
    "            features = features.T\n",
    "            \n",
    "            # Replace NaN and Inf with zeros\n",
    "            features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            \n",
    "            # Clip extreme values\n",
    "            features = np.clip(features, -1e6, 1e6)\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {audio_path}: {str(e)}\")\n",
    "            # Return zero features on error - calculate expected frames\n",
    "            expected_frames = int((self.config.SAMPLE_RATE * self.config.DURATION) / self.config.HOP_LENGTH) + 1\n",
    "            return np.zeros((expected_frames, self.config.INPUT_SIZE))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        candidate_id = self.candidate_ids[idx]\n",
    "        \n",
    "        # Construct audio paths\n",
    "        cough_audio_path = self.cough_path / candidate_id / 'cough.wav'\n",
    "        vowel_audio_path = self.vowel_path / candidate_id / 'vowel.wav'\n",
    "        \n",
    "        # Load and extract features\n",
    "        cough_features = self._load_and_extract_features(cough_audio_path)\n",
    "        vowel_features = self._load_and_extract_features(vowel_audio_path)\n",
    "        \n",
    "        # Combine features based on mode\n",
    "        if self.config.COMBINE_MODE == \"concat\":\n",
    "            # Concatenate along feature dimension\n",
    "            combined = np.concatenate([cough_features, vowel_features], axis=1)\n",
    "        elif self.config.COMBINE_MODE == \"average\":\n",
    "            # Average the features\n",
    "            combined = (cough_features + vowel_features) / 2.0\n",
    "        elif self.config.COMBINE_MODE == \"cough_only\":\n",
    "            combined = cough_features\n",
    "        elif self.config.COMBINE_MODE == \"vowel_only\":\n",
    "            combined = vowel_features\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown combine_mode: {self.config.COMBINE_MODE}\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        audio_tensor = torch.FloatTensor(combined)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return audio_tensor, candidate_id\n",
    "        else:\n",
    "            label = torch.LongTensor([self.labels[idx]])[0]\n",
    "            return audio_tensor, label, candidate_id\n",
    "\n",
    "\n",
    "# Custom collate function for variable-length sequences\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function to handle variable-length sequences\"\"\"\n",
    "    if len(batch[0]) == 2:\n",
    "        # Test set (audio, candidate_id)\n",
    "        audio_features = [item[0] for item in batch]\n",
    "        candidate_ids = [item[1] for item in batch]\n",
    "        \n",
    "        # Pad audio sequences\n",
    "        audio_padded = nn.utils.rnn.pad_sequence(audio_features, batch_first=True)\n",
    "        lengths = torch.LongTensor([len(x) for x in audio_features])\n",
    "        \n",
    "        return audio_padded, lengths, candidate_ids\n",
    "    else:\n",
    "        # Training set (audio, label, candidate_id)\n",
    "        audio_features = [item[0] for item in batch]\n",
    "        labels = torch.stack([item[1] for item in batch])\n",
    "        candidate_ids = [item[2] for item in batch]\n",
    "        \n",
    "        # Pad audio sequences\n",
    "        audio_padded = nn.utils.rnn.pad_sequence(audio_features, batch_first=True)\n",
    "        lengths = torch.LongTensor([len(x) for x in audio_features])\n",
    "        \n",
    "        return audio_padded, lengths, labels, candidate_ids\n",
    "\n",
    "\n",
    "print(\"Dataset class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558b410",
   "metadata": {},
   "source": [
    "## 4b. Focal Loss for Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9df847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal Loss defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for handling class imbalance\n",
    "    FL(p_t) = -alpha_t * (1 - p_t)^gamma * log(p_t)\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', label_smoothing=0.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha  # Class weights (optional)\n",
    "        self.gamma = gamma  # Focusing parameter\n",
    "        self.reduction = reduction\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: (batch_size, num_classes) - logits\n",
    "            targets: (batch_size,) - class indices\n",
    "        \"\"\"\n",
    "        ce_loss = nn.functional.cross_entropy(\n",
    "            inputs, targets, reduction='none', \n",
    "            weight=self.alpha, label_smoothing=self.label_smoothing\n",
    "        )\n",
    "        p_t = torch.exp(-ce_loss)  # Probability of true class\n",
    "        focal_loss = (1 - p_t) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "print(\"Focal Loss defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc86f2",
   "metadata": {},
   "source": [
    "## 5. Unidirectional LSTM Model (Simplified Architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fa5ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Applied balanced weight initialization\n",
      "\n",
      "Model Architecture (Simplified Unidirectional LSTM):\n",
      "RespiratoryLSTM(\n",
      "  (batch_norm1): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm1): LSTM(120, 128, batch_first=True)\n",
      "  (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lstm2): LSTM(128, 128, batch_first=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 260,979\n",
      "Trainable parameters: 260,979\n",
      "\n",
      "Model uses 2-layer LSTM without attention mechanism\n",
      "Takes last timestep output for classification\n"
     ]
    }
   ],
   "source": [
    "class RespiratoryLSTM(nn.Module):\n",
    "    \"\"\"Simplified LSTM-based model for respiratory disease classification\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(RespiratoryLSTM, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        # Calculate actual input size based on combine mode\n",
    "        if config.COMBINE_MODE == \"concat\":\n",
    "            input_size = config.INPUT_SIZE * 2  # 120 features (60 cough + 60 vowel)\n",
    "        else:\n",
    "            input_size = config.INPUT_SIZE  # 60 features\n",
    "        \n",
    "        # First batch norm and LSTM layer\n",
    "        self.batch_norm1 = nn.BatchNorm1d(input_size)\n",
    "        self.lstm1 = nn.LSTM(input_size, config.HIDDEN_SIZE, batch_first=True)\n",
    "        \n",
    "        # Second batch norm and LSTM layer\n",
    "        self.batch_norm2 = nn.BatchNorm1d(config.HIDDEN_SIZE)\n",
    "        self.lstm2 = nn.LSTM(config.HIDDEN_SIZE, config.HIDDEN_SIZE, batch_first=True)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(config.DROPOUT)\n",
    "        self.fc = nn.Linear(config.HIDDEN_SIZE, config.OUTPUT_SIZE)\n",
    "    \n",
    "    def forward(self, x, lengths=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, feature_dim)\n",
    "            lengths: (batch_size,) actual lengths of sequences (optional, not used in this simplified version)\n",
    "        \"\"\"\n",
    "        # First LSTM block\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm1(x)\n",
    "        \n",
    "        # Second LSTM block\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        # Take last time step output\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights to avoid initial bias toward any class\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                if 'lstm' in name:\n",
    "                    # LSTM weights - orthogonal initialization\n",
    "                    nn.init.orthogonal_(param)\n",
    "                elif 'batch_norm' in name:\n",
    "                    # BatchNorm weights\n",
    "                    nn.init.ones_(param)\n",
    "                elif len(param.shape) >= 2:\n",
    "                    # Linear layers - Xavier initialization\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                # All biases to zero\n",
    "                nn.init.zeros_(param)\n",
    "        \n",
    "        # Special: Initialize final classifier layer with small weights\n",
    "        # to start with near-uniform predictions\n",
    "        nn.init.xavier_uniform_(self.fc.weight, gain=0.1)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path, model):\n",
    "    \"\"\"Load model checkpoint with flexible state dict matching\"\"\"\n",
    "    checkpoint_dict = torch.load(checkpoint_path, weights_only=True, map_location='cpu')\n",
    "    saved_state_dict = checkpoint_dict['model']\n",
    "    state_dict = model.state_dict()\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for k, v in state_dict.items():\n",
    "        try:\n",
    "            new_state_dict[k] = saved_state_dict[k]\n",
    "        except:\n",
    "            new_state_dict[k] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = RespiratoryLSTM(config).to(device)\n",
    "\n",
    "# Apply custom weight initialization to avoid class bias\n",
    "model._init_weights()\n",
    "print(\"✓ Applied balanced weight initialization\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nModel Architecture (Simplified Unidirectional LSTM):\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(\"\\nModel uses 2-layer LSTM without attention mechanism\")\n",
    "print(\"Takes last timestep output for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc59a8e",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "945d7e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Apply Mixup augmentation\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute Mixup loss\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, config, use_mixup=False):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for audio, lengths, labels, _ in progress_bar:\n",
    "        audio = audio.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Check for NaN in input data\n",
    "        if torch.isnan(audio).any():\n",
    "            print(\"Warning: NaN detected in input data, skipping batch\")\n",
    "            continue\n",
    "        \n",
    "        # Apply Mixup augmentation\n",
    "        if use_mixup and config.MIXUP_ALPHA > 0:\n",
    "            audio, labels_a, labels_b, lam = mixup_data(audio, labels, config.MIXUP_ALPHA)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(audio, lengths)\n",
    "        \n",
    "        # Check for NaN in outputs\n",
    "        if torch.isnan(outputs).any():\n",
    "            print(\"Warning: NaN in model outputs, skipping batch\")\n",
    "            continue\n",
    "        \n",
    "        # Compute loss (with or without mixup)\n",
    "        if use_mixup and config.MIXUP_ALPHA > 0:\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "            # For tracking, use original labels\n",
    "            all_labels.extend(labels_a.cpu().numpy())\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Check for NaN in loss\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Warning: NaN loss detected, skipping batch\")\n",
    "            continue\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent explosion\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.GRADIENT_CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else float('inf')\n",
    "    accuracy = accuracy_score(all_labels, all_preds) if len(all_labels) > 0 else 0.0\n",
    "    \n",
    "    # Check prediction distribution\n",
    "    unique_preds, pred_counts = np.unique(all_preds, return_counts=True)\n",
    "    pred_dist = {int(cls): int(cnt) for cls, cnt in zip(unique_preds, pred_counts)}\n",
    "    \n",
    "    return avg_loss, accuracy, pred_dist\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for audio, lengths, labels, _ in tqdm(dataloader, desc=\"Validation\"):\n",
    "            audio = audio.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(audio, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            total_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_labels, all_probs\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_probs=None, title=\"Evaluation\"):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = fbeta_score(y_true, y_pred, beta=1, average='weighted', zero_division=0)\n",
    "    f2 = fbeta_score(y_true, y_pred, beta=2, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  F2 Score:  {f2:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    class_names = ['Healthy', 'COPD', 'Asthma']\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'f2_score': f2,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_names = ['Healthy', 'COPD', 'Asthma']\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc85259",
   "metadata": {},
   "source": [
    "## 7. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25b13a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (546, 11)\n",
      "Test data shape: (338, 10)\n",
      "\n",
      "============================================================\n",
      "Filtering out samples with missing audio files...\n",
      "Training: 546 -> 533 (removed 13 with missing files)\n",
      "Test: 338 total, 2 with missing files (will use default prediction)\n",
      "============================================================\n",
      "\n",
      "Class distribution in training data (after filtering):\n",
      "disease\n",
      "0    137\n",
      "1    238\n",
      "2    158\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class percentages:\n",
      "  Class 0 (Healthy): 25.70%\n",
      "  Class 1 (COPD): 44.65%\n",
      "  Class 2 (Asthma): 29.64%\n",
      "\n",
      "Data split:\n",
      "  Training: 426\n",
      "  Validation: 107\n",
      "  Test: 338\n",
      "\n",
      "Training set class distribution:\n",
      "  Class 0 (Healthy): 110 samples (25.8%)\n",
      "  Class 1 (COPD): 190 samples (44.6%)\n",
      "  Class 2 (Asthma): 126 samples (29.6%)\n",
      "\n",
      "Validation set class distribution:\n",
      "  Class 0 (Healthy): 27 samples (25.2%)\n",
      "  Class 1 (COPD): 48 samples (44.9%)\n",
      "  Class 2 (Asthma): 32 samples (29.9%)\n",
      "\n",
      "============================================================\n",
      "Creating datasets...\n",
      "\n",
      "Dataloaders created:\n",
      "  Train batches: 27\n",
      "  Val batches: 7\n",
      "  Test batches: 22\n"
     ]
    }
   ],
   "source": [
    "# Load train/test split\n",
    "train_df = pd.read_csv(config.TRAIN_CSV)\n",
    "test_df = pd.read_csv(config.TEST_CSV)\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTER OUT SAMPLES WITH MISSING AUDIO FILES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Filtering out samples with missing audio files...\")\n",
    "\n",
    "def check_audio_exists(candidate_id, config):\n",
    "    \"\"\"Check if both cough and vowel audio files exist\"\"\"\n",
    "    cough_path = config.COUGH_PATH / candidate_id / 'cough.wav'\n",
    "    vowel_path = config.VOWEL_PATH / candidate_id / 'vowel.wav'\n",
    "    return cough_path.exists() and vowel_path.exists()\n",
    "\n",
    "# Filter training data\n",
    "original_train_count = len(train_df)\n",
    "train_df['has_audio'] = train_df['candidateID'].apply(lambda x: check_audio_exists(x, config))\n",
    "train_df_filtered = train_df[train_df['has_audio']].copy()\n",
    "removed_train = original_train_count - len(train_df_filtered)\n",
    "\n",
    "print(f\"Training: {original_train_count} -> {len(train_df_filtered)} (removed {removed_train} with missing files)\")\n",
    "\n",
    "# Filter test data (for prediction, we'll handle missing differently)\n",
    "original_test_count = len(test_df)\n",
    "test_df['has_audio'] = test_df['candidateID'].apply(lambda x: check_audio_exists(x, config))\n",
    "test_missing_ids = test_df[~test_df['has_audio']]['candidateID'].tolist()\n",
    "print(f\"Test: {original_test_count} total, {len(test_missing_ids)} with missing files (will use default prediction)\")\n",
    "\n",
    "# Use filtered training data\n",
    "train_df = train_df_filtered\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nClass distribution in training data (after filtering):\")\n",
    "print(train_df['disease'].value_counts().sort_index())\n",
    "print(f\"\\nClass percentages:\")\n",
    "class_dist = train_df['disease'].value_counts(normalize=True).sort_index() * 100\n",
    "for cls, pct in class_dist.items():\n",
    "    class_name = ['Healthy', 'COPD', 'Asthma'][int(cls)]\n",
    "    print(f\"  Class {cls} ({class_name}): {pct:.2f}%\")\n",
    "\n",
    "# Split training data into train and validation\n",
    "train_ids = train_df['candidateID'].values\n",
    "train_labels = train_df['disease'].values\n",
    "\n",
    "train_ids, val_ids, train_labels, val_labels = train_test_split(\n",
    "    train_ids, train_labels, \n",
    "    test_size=config.VAL_SPLIT, \n",
    "    random_state=42,\n",
    "    stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training: {len(train_ids)}\")\n",
    "print(f\"  Validation: {len(val_ids)}\")\n",
    "print(f\"  Test: {len(test_df)}\")\n",
    "\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    class_name = ['Healthy', 'COPD', 'Asthma'][int(cls)]\n",
    "    print(f\"  Class {cls} ({class_name}): {cnt} samples ({cnt/len(train_labels)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nValidation set class distribution:\")\n",
    "unique, counts = np.unique(val_labels, return_counts=True)\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    class_name = ['Healthy', 'COPD', 'Asthma'][int(cls)]\n",
    "    print(f\"  Class {cls} ({class_name}): {cnt} samples ({cnt/len(val_labels)*100:.1f}%)\")\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = RespiratoryDataset(train_ids, train_labels, config, is_test=False, augment=config.USE_AUGMENTATION)\n",
    "val_dataset = RespiratoryDataset(val_ids, val_labels, config, is_test=False, augment=False)  # No augmentation for validation\n",
    "test_dataset = RespiratoryDataset(test_df['candidateID'].values, None, config, is_test=True, augment=False)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\nDataloaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1fed6",
   "metadata": {},
   "source": [
    "## 8. Train Unified Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc44998",
   "metadata": {},
   "source": [
    "## 7b. Alternative Strategies for Class Imbalance (Beyond Attention)\n",
    "\n",
    "If the model is collapsing to one class, try these approaches:\n",
    "\n",
    "### Option 1: Focal Loss (Already Available)\n",
    "```python\n",
    "# Use Focal Loss instead of CrossEntropyLoss\n",
    "criterion = FocalLoss(alpha=class_weights, gamma=2.0, label_smoothing=0.1)\n",
    "```\n",
    "\n",
    "### Option 2: Strong Data Augmentation\n",
    "- Increase augmentation strength\n",
    "- Apply multiple augmentations per sample\n",
    "- Use SpecAugment (time/frequency masking)\n",
    "\n",
    "### Option 3: Class Balancing via Sampling\n",
    "- Oversample minority classes\n",
    "- Undersample majority class\n",
    "- Use WeightedRandomSampler\n",
    "\n",
    "### Option 4: Two-Stage Training\n",
    "- First train on balanced subset\n",
    "- Then fine-tune on full dataset\n",
    "\n",
    "### Option 5: Ensemble Methods\n",
    "- Train multiple models with different random seeds\n",
    "- Combine predictions via voting/averaging\n",
    "\n",
    "### Option 6: Feature Engineering\n",
    "- Use different audio features (spectrograms, wavelet)\n",
    "- Normalize features per-sample or globally\n",
    "- Add statistical features (mean, std, skewness)\n",
    "\n",
    "### Option 7: Stronger Regularization\n",
    "- Increase dropout (0.5-0.6)\n",
    "- Add L2 regularization\n",
    "- Use batch normalization more aggressively\n",
    "\n",
    "### Option 8: Different Loss Functions\n",
    "- Use Dice Loss\n",
    "- Use Balanced CrossEntropy\n",
    "- Combine multiple losses\n",
    "\n",
    "**Let's implement the most effective ones below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcf1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created balanced sampler for training\n",
      "  This ensures each class appears equally in batches\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  This ensures each class appears equally in batches\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# STRATEGY 2: Class-Balanced Focal Loss\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Use focal loss with strong class weights\u001b[39;00m\n\u001b[32m     39\u001b[39m focal_criterion = FocalLoss(\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     alpha=\u001b[43mclass_weights\u001b[49m, \n\u001b[32m     41\u001b[39m     gamma=\u001b[32m3.0\u001b[39m,  \u001b[38;5;66;03m# Higher gamma focuses more on hard examples\u001b[39;00m\n\u001b[32m     42\u001b[39m     label_smoothing=\u001b[32m0.1\u001b[39m\n\u001b[32m     43\u001b[39m )\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Focal Loss with gamma=3.0 ready\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# STRATEGY 3: Temperature Scaling for Better Calibration\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'class_weights' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STRATEGY 1: Weighted Random Sampler for Balanced Batches\n",
    "# ============================================================================\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "def create_balanced_sampler(labels):\n",
    "    \"\"\"Create a sampler that balances classes in each batch\"\"\"\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = class_weights[labels]\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "# Create balanced sampler for training\n",
    "train_sampler = create_balanced_sampler(train_labels)\n",
    "\n",
    "# Recreate train loader with balanced sampler\n",
    "train_loader_balanced = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    sampler=train_sampler,  # Use sampler instead of shuffle\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"✓ Created balanced sampler for training\")\n",
    "print(f\"  This ensures each class appears equally in batches\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY 2: Class-Balanced Focal Loss\n",
    "# ============================================================================\n",
    "# Compute class weights for focal loss\n",
    "class_counts = np.bincount(train_labels)\n",
    "class_weights_np = 1.0 / class_counts\n",
    "class_weights = torch.FloatTensor(class_weights_np).to(device)\n",
    "\n",
    "# Use focal loss with strong class weights\n",
    "focal_criterion = FocalLoss(\n",
    "    alpha=class_weights, \n",
    "    gamma=3.0,  # Higher gamma focuses more on hard examples\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "print(\"✓ Focal Loss with gamma=3.0 ready\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY 3: Temperature Scaling for Better Calibration\n",
    "# ============================================================================\n",
    "class TemperatureScaledModel(nn.Module):\n",
    "    \"\"\"Wraps model with temperature scaling for better probability calibration\"\"\"\n",
    "    def __init__(self, model, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, x, lengths=None):\n",
    "        logits = self.model(x, lengths)\n",
    "        return logits / self.temperature\n",
    "\n",
    "# Optional: wrap model with temperature scaling\n",
    "# model_scaled = TemperatureScaledModel(model, temperature=2.0).to(device)\n",
    "\n",
    "print(\"✓ Temperature scaling available (optional)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY 4: Per-Class Loss Monitoring\n",
    "# ============================================================================\n",
    "def compute_per_class_loss(outputs, labels, num_classes=3):\n",
    "    \"\"\"Compute loss for each class separately\"\"\"\n",
    "    criterion_per_class = nn.CrossEntropyLoss(reduction='none')\n",
    "    losses = criterion_per_class(outputs, labels)\n",
    "    \n",
    "    per_class_losses = {}\n",
    "    for c in range(num_classes):\n",
    "        mask = labels == c\n",
    "        if mask.sum() > 0:\n",
    "            per_class_losses[c] = losses[mask].mean().item()\n",
    "        else:\n",
    "            per_class_losses[c] = 0.0\n",
    "    \n",
    "    return per_class_losses\n",
    "\n",
    "print(\"✓ Per-class loss monitoring function ready\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STRATEGY 5: Gradient Surgery (Prevent Dominant Class Gradients)\n",
    "# ============================================================================\n",
    "def balance_gradients_by_class(model, outputs, labels, num_classes=3):\n",
    "    \"\"\"Scale gradients inversely proportional to class frequency\"\"\"\n",
    "    class_counts = torch.bincount(labels, minlength=num_classes).float()\n",
    "    total = class_counts.sum()\n",
    "    class_weights = total / (num_classes * class_counts + 1e-8)\n",
    "    \n",
    "    # Weight samples by their class\n",
    "    sample_weights = class_weights[labels]\n",
    "    weighted_outputs = outputs * sample_weights.unsqueeze(1)\n",
    "    \n",
    "    return weighted_outputs\n",
    "\n",
    "print(\"✓ Gradient balancing function ready\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Choose which strategies to use\n",
    "# ============================================================================\n",
    "USE_BALANCED_SAMPLER = True\n",
    "USE_FOCAL_LOSS = True\n",
    "USE_TEMPERATURE_SCALING = False\n",
    "USE_GRADIENT_BALANCING = False\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SELECTED STRATEGIES:\")\n",
    "print(f\"  Balanced Sampler: {USE_BALANCED_SAMPLER}\")\n",
    "print(f\"  Focal Loss: {USE_FOCAL_LOSS}\")\n",
    "print(f\"  Temperature Scaling: {USE_TEMPERATURE_SCALING}\")\n",
    "print(f\"  Gradient Balancing: {USE_GRADIENT_BALANCING}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704728c",
   "metadata": {},
   "source": [
    "## 7c. Quick Configuration Changes to Try\n",
    "\n",
    "If model still collapses, try these **configuration changes** (edit cell 4 above):\n",
    "\n",
    "### 1. **Increase Dropout** (currently 0.4)\n",
    "```python\n",
    "DROPOUT = 0.6  # Much stronger regularization\n",
    "```\n",
    "\n",
    "### 2. **Reduce Learning Rate** (currently 0.0005)\n",
    "```python\n",
    "LEARNING_RATE = 0.0001  # Slower, more careful learning\n",
    "```\n",
    "\n",
    "### 3. **Disable Mixup** (might be confusing the model)\n",
    "```python\n",
    "USE_AUGMENTATION = False  # Train without augmentation first\n",
    "MIXUP_ALPHA = 0.0\n",
    "```\n",
    "\n",
    "### 4. **Increase Batch Size** (currently 16)\n",
    "```python\n",
    "BATCH_SIZE = 32  # More stable gradients\n",
    "```\n",
    "\n",
    "### 5. **Change Combine Mode** (currently \"concat\")\n",
    "```python\n",
    "COMBINE_MODE = \"average\"  # Simpler feature combination\n",
    "# or try:\n",
    "COMBINE_MODE = \"cough_only\"  # Use only cough data\n",
    "```\n",
    "\n",
    "### 6. **Reduce Model Complexity** (currently 128)\n",
    "```python\n",
    "HIDDEN_SIZE = 64  # Smaller, simpler model\n",
    "```\n",
    "\n",
    "### 7. **Stronger Class Weights**\n",
    "In cell 7b below, change:\n",
    "```python\n",
    "class_weights = compute_class_weights(train_labels, method='balanced')  # Instead of 'sqrt'\n",
    "```\n",
    "\n",
    "**Recommended First Try:**\n",
    "1. Set `DROPOUT = 0.6`\n",
    "2. Set `LEARNING_RATE = 0.0001`\n",
    "3. Set `USE_AUGMENTATION = False`\n",
    "4. Use Balanced Sampler + Focal Loss (already in cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50559e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emergency reset function available - uncomment to use if needed\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EMERGENCY FIX: If model still collapses, run this to reset everything\n",
    "# ============================================================================\n",
    "\n",
    "def emergency_reset_and_retrain():\n",
    "    \"\"\"\n",
    "    Complete reset with most aggressive anti-collapse settings.\n",
    "    Use this if model keeps predicting only one class.\n",
    "    \"\"\"\n",
    "    print(\"EMERGENCY RESET - AGGRESSIVE ANTI-COLLAPSE MODE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Recreate model with stronger regularization\n",
    "    class AggressiveConfig:\n",
    "        def __init__(self, base_config):\n",
    "            for key, val in vars(base_config).items():\n",
    "                setattr(self, key, val)\n",
    "            # Override critical parameters\n",
    "            self.DROPOUT = 0.7  # Very strong dropout\n",
    "            self.LEARNING_RATE = 0.00005  # Very slow learning\n",
    "            self.HIDDEN_SIZE = 64  # Simpler model\n",
    "            self.USE_AUGMENTATION = False  # No augmentation\n",
    "            self.MIXUP_ALPHA = 0.0\n",
    "    \n",
    "    aggressive_config = AggressiveConfig(config)\n",
    "    \n",
    "    # 2. Create new model\n",
    "    new_model = RespiratoryLSTM(aggressive_config).to(device)\n",
    "    new_model._init_weights()\n",
    "    \n",
    "    # 3. Use strongest class weighting\n",
    "    strong_weights = compute_class_weights(train_labels, method='balanced')\n",
    "    strong_weights = strong_weights.to(device)\n",
    "    strong_weights = strong_weights * 2.0  # Double the effect!\n",
    "    \n",
    "    # 4. Focal loss with very high gamma\n",
    "    strong_criterion = FocalLoss(alpha=strong_weights, gamma=5.0, label_smoothing=0.0)\n",
    "    \n",
    "    # 5. Conservative optimizer\n",
    "    conservative_optimizer = optim.AdamW(\n",
    "        new_model.parameters(), \n",
    "        lr=aggressive_config.LEARNING_RATE,\n",
    "        weight_decay=0.01  # Strong weight decay\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Created aggressive anti-collapse model\")\n",
    "    print(f\"  Dropout: {aggressive_config.DROPOUT}\")\n",
    "    print(f\"  Learning Rate: {aggressive_config.LEARNING_RATE}\")\n",
    "    print(f\"  Hidden Size: {aggressive_config.HIDDEN_SIZE}\")\n",
    "    print(f\"  Focal gamma: 5.0\")\n",
    "    print(f\"  Class weights: {strong_weights.cpu().numpy()}\")\n",
    "    \n",
    "    return new_model, strong_criterion, conservative_optimizer, aggressive_config\n",
    "\n",
    "# Uncomment below to use emergency mode:\n",
    "# model, criterion, optimizer, config = emergency_reset_and_retrain()\n",
    "# Then rerun the training loop\n",
    "\n",
    "print(\"Emergency reset function available - uncomment to use if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f483e28",
   "metadata": {},
   "source": [
    "## 7d. 🚨 IMMEDIATE FIX - Stop Training and Apply These Changes\n",
    "\n",
    "**Your model is still collapsing! Here's what to do NOW:**\n",
    "\n",
    "### **STEP 1: Stop the current training (interrupt the cell)**\n",
    "\n",
    "### **STEP 2: Go back to Configuration cell (cell 4) and change these:**\n",
    "\n",
    "```python\n",
    "# In Config class, change these values:\n",
    "DROPOUT = 0.7              # Was 0.4 - INCREASE THIS\n",
    "LEARNING_RATE = 0.00005    # Was 0.0005 - REDUCE BY 10X\n",
    "USE_AUGMENTATION = False   # Was True - DISABLE THIS\n",
    "HIDDEN_SIZE = 64           # Was 128 - REDUCE BY HALF\n",
    "COMBINE_MODE = \"average\"   # Was \"concat\" - SIMPLER COMBINATION\n",
    "```\n",
    "\n",
    "### **STEP 3: Run the emergency reset below**\n",
    "\n",
    "This will use the most aggressive settings to prevent collapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🚨 APPLYING EMERGENCY ANTI-COLLAPSE CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "✓ Emergency Configuration Applied:\n",
      "  Hidden Size: 32 (was 128)\n",
      "  Dropout: 0.8 (was 0.4)\n",
      "  Learning Rate: 1e-05 (was 0.0005)\n",
      "  Batch Size: 8 (was 16)\n",
      "  Combine Mode: average (was concat)\n",
      "  Augmentation: False (was True)\n",
      "\n",
      "🔄 Recreating datasets with emergency config...\n",
      "\n",
      "🏗️ Creating emergency model...\n",
      "\n",
      "Class Imbalance Analysis (method='balanced'):\n",
      "============================================================\n",
      "Class           Count      Percentage      Weight    \n",
      "------------------------------------------------------------\n",
      "Healthy         110        25.82           1.2909    \n",
      "COPD            190        44.60           0.7474    \n",
      "Asthma          126        29.58           1.1270    \n",
      "============================================================\n",
      "Weight ratio (max/min): 1.73x\n",
      "\n",
      "🔥 Using TRIPLED class weights:\n",
      "  [3.8727272 2.2421052 3.3809524]\n",
      "\n",
      "✓ Emergency model parameters: 20,763 (much smaller!)\n",
      "\n",
      "======================================================================\n",
      " EMERGENCY SETUP COMPLETE\n",
      "======================================================================\n",
      "\n",
      " IMPORTANT: Use these variables in the training loop:\n",
      "  - model = emergency_model\n",
      "  - criterion = emergency_criterion\n",
      "  - optimizer = emergency_optimizer\n",
      "  - scheduler = emergency_scheduler\n",
      "  - config = emergency_config\n",
      "  - active_train_loader = emergency_train_loader\n",
      "  - val_loader = emergency_val_loader\n",
      "\n",
      "Or run the emergency training loop in the next cell!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🚨 EMERGENCY SOLUTION - Use this to retrain with proper settings\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"🚨 APPLYING EMERGENCY ANTI-COLLAPSE CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create aggressive configuration\n",
    "class EmergencyConfig:\n",
    "    # Paths (keep same)\n",
    "    BASE_PATH = Path('/mnt/ml_storage/Final_Project/SOURCE2')\n",
    "    COUGH_PATH = BASE_PATH / 'dataclean_cough_1'\n",
    "    VOWEL_PATH = BASE_PATH / 'dataclean_vowel_1'\n",
    "    TRAIN_CSV = BASE_PATH / 'train.csv'\n",
    "    TEST_CSV = BASE_PATH / 'test.csv'\n",
    "    MODEL_DIR = BASE_PATH / 'models'\n",
    "    \n",
    "    # Audio parameters (keep same)\n",
    "    SAMPLE_RATE = 16000\n",
    "    DURATION = 2.0\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    WIN_LENGTH = 2048\n",
    "    N_MFCC = 20\n",
    "    N_MELS = 64\n",
    "    \n",
    "    # Model parameters - AGGRESSIVE ANTI-COLLAPSE\n",
    "    INPUT_SIZE = 60\n",
    "    HIDDEN_SIZE = 32  # 🔥 MUCH SMALLER - was 128\n",
    "    NUM_LAYERS = 2\n",
    "    OUTPUT_SIZE = 3\n",
    "    DROPOUT = 0.8  # 🔥 VERY HIGH - was 0.4\n",
    "    BIDIRECTIONAL = False\n",
    "    \n",
    "    # Training parameters - VERY CONSERVATIVE\n",
    "    BATCH_SIZE = 8  # 🔥 SMALLER - was 16\n",
    "    LEARNING_RATE = 0.00001  # 🔥 VERY LOW - was 0.0005\n",
    "    NUM_EPOCHS = 150\n",
    "    VAL_SPLIT = 0.2\n",
    "    PATIENCE = 35  # More patience\n",
    "    GRADIENT_CLIP = 0.5  # 🔥 STRICTER - was 1.0\n",
    "    WEIGHT_DECAY = 0.01  # 🔥 STRONGER - was 0.001\n",
    "    \n",
    "    # Data augmentation - DISABLED\n",
    "    USE_AUGMENTATION = False  # 🔥 NO MIXUP\n",
    "    MIXUP_ALPHA = 0.0\n",
    "    \n",
    "    # Audio combination - SIMPLER\n",
    "    COMBINE_MODE = \"average\"  # 🔥 SIMPLER - was \"concat\"\n",
    "\n",
    "# Apply emergency config\n",
    "emergency_config = EmergencyConfig()\n",
    "emergency_config.MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\n✓ Emergency Configuration Applied:\")\n",
    "print(f\"  Hidden Size: {emergency_config.HIDDEN_SIZE} (was 128)\")\n",
    "print(f\"  Dropout: {emergency_config.DROPOUT} (was 0.4)\")\n",
    "print(f\"  Learning Rate: {emergency_config.LEARNING_RATE} (was 0.0005)\")\n",
    "print(f\"  Batch Size: {emergency_config.BATCH_SIZE} (was 16)\")\n",
    "print(f\"  Combine Mode: {emergency_config.COMBINE_MODE} (was concat)\")\n",
    "print(f\"  Augmentation: {emergency_config.USE_AUGMENTATION} (was True)\")\n",
    "\n",
    "# Recreate datasets with new config\n",
    "print(\"\\n🔄 Recreating datasets with emergency config...\")\n",
    "emergency_train_dataset = RespiratoryDataset(\n",
    "    train_ids, train_labels, emergency_config, \n",
    "    is_test=False, augment=emergency_config.USE_AUGMENTATION\n",
    ")\n",
    "emergency_val_dataset = RespiratoryDataset(\n",
    "    val_ids, val_labels, emergency_config, \n",
    "    is_test=False, augment=False\n",
    ")\n",
    "emergency_test_dataset = RespiratoryDataset(\n",
    "    test_df['candidateID'].values, None, emergency_config, \n",
    "    is_test=True, augment=False\n",
    ")\n",
    "\n",
    "# Create balanced sampler for emergency config\n",
    "emergency_train_sampler = create_balanced_sampler(train_labels)\n",
    "\n",
    "# Create dataloaders with emergency config\n",
    "emergency_train_loader = DataLoader(\n",
    "    emergency_train_dataset,\n",
    "    batch_size=emergency_config.BATCH_SIZE,\n",
    "    sampler=emergency_train_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "emergency_val_loader = DataLoader(\n",
    "    emergency_val_dataset,\n",
    "    batch_size=emergency_config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "emergency_test_loader = DataLoader(\n",
    "    emergency_test_dataset,\n",
    "    batch_size=emergency_config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Create emergency model\n",
    "print(\"\\n🏗️ Creating emergency model...\")\n",
    "emergency_model = RespiratoryLSTM(emergency_config).to(device)\n",
    "emergency_model._init_weights()\n",
    "\n",
    "# Use VERY STRONG class weights\n",
    "emergency_class_weights = compute_class_weights(train_labels, method='balanced')\n",
    "emergency_class_weights = emergency_class_weights.to(device)\n",
    "emergency_class_weights = emergency_class_weights * 3.0  # 🔥 TRIPLE THE WEIGHTS\n",
    "\n",
    "print(f\"\\n🔥 Using TRIPLED class weights:\")\n",
    "print(f\"  {emergency_class_weights.cpu().numpy()}\")\n",
    "\n",
    "# Focal loss with VERY HIGH gamma\n",
    "emergency_criterion = FocalLoss(\n",
    "    alpha=emergency_class_weights, \n",
    "    gamma=5.0,  # 🔥 VERY HIGH - was 3.0\n",
    "    label_smoothing=0.0  # No label smoothing\n",
    ")\n",
    "\n",
    "# Very conservative optimizer\n",
    "emergency_optimizer = optim.AdamW(\n",
    "    emergency_model.parameters(), \n",
    "    lr=emergency_config.LEARNING_RATE,\n",
    "    weight_decay=emergency_config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "emergency_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    emergency_optimizer, T_0=15, T_mult=2, eta_min=1e-7\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "emergency_params = sum(p.numel() for p in emergency_model.parameters())\n",
    "print(f\"\\n✓ Emergency model parameters: {emergency_params:,} (much smaller!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" EMERGENCY SETUP COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n IMPORTANT: Use these variables in the training loop:\")\n",
    "print(\"  - model = emergency_model\")\n",
    "print(\"  - criterion = emergency_criterion\")\n",
    "print(\"  - optimizer = emergency_optimizer\")\n",
    "print(\"  - scheduler = emergency_scheduler\")\n",
    "print(\"  - config = emergency_config\")\n",
    "print(\"  - active_train_loader = emergency_train_loader\")\n",
    "print(\"  - val_loader = emergency_val_loader\")\n",
    "print(\"\\nOr run the emergency training loop in the next cell!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433cb9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EMERGENCY TRAINING MODE - ANTI-COLLAPSE CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "🔥 Starting EMERGENCY training:\n",
      "  Model size: 20,763 parameters\n",
      "  Dropout: 0.8\n",
      "  Learning rate: 1e-05\n",
      "  Batch size: 8\n",
      "  Focal gamma: 5.0\n",
      "  Class weights: TRIPLED\n",
      "\n",
      "This should prevent class collapse!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Epoch 1/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:03<00:00, 15.62it/s, loss=2.6200]\n",
      "Training: 100%|██████████| 54/54 [00:03<00:00, 15.62it/s, loss=2.6200]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.08it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9151, Train Acc: 0.3474\n",
      "  Val Loss: 2.7089, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=38, Class 1=313, Class 2=75\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  💾 Best model saved! (F1: 0.2065, Acc: 0.4486)\n",
      "\n",
      "======================================================================\n",
      "Epoch 2/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.59it/s, loss=4.0638]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.59it/s, loss=4.0638]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.93it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9965, Train Acc: 0.3474\n",
      "  Val Loss: 2.7090, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=36, Class 1=305, Class 2=85\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (1/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 3/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.67it/s, loss=1.6415]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.67it/s, loss=1.6415]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.90it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9397, Train Acc: 0.3216\n",
      "  Val Loss: 2.7090, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=41, Class 1=279, Class 2=106\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (2/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 4/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.54it/s, loss=2.4632]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.54it/s, loss=2.4632]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.06it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0524, Train Acc: 0.3404\n",
      "  Val Loss: 2.7091, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=48, Class 1=286, Class 2=92\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (3/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 5/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.79it/s, loss=1.6123]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.79it/s, loss=1.6123]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.32it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8701, Train Acc: 0.3404\n",
      "  Val Loss: 2.7091, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=53, Class 1=294, Class 2=79\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (4/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 6/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.40it/s, loss=3.6845]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.40it/s, loss=3.6845]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.43it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9991, Train Acc: 0.3286\n",
      "  Val Loss: 2.7093, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=64, Class 1=269, Class 2=93\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (5/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 7/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.65it/s, loss=2.7110]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.65it/s, loss=2.7110]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.37it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9701, Train Acc: 0.3357\n",
      "  Val Loss: 2.7092, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000006\n",
      "  Train Preds: Class 0=37, Class 1=269, Class 2=120\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (6/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 8/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.89it/s, loss=2.8088]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.89it/s, loss=2.8088]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.16it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8944, Train Acc: 0.3803\n",
      "  Val Loss: 2.7092, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000005\n",
      "  Train Preds: Class 0=58, Class 1=268, Class 2=100\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (7/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 9/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.08it/s, loss=3.7869]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.08it/s, loss=3.7869]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 15.20it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9958, Train Acc: 0.3052\n",
      "  Val Loss: 2.7093, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000004\n",
      "  Train Preds: Class 0=51, Class 1=283, Class 2=92\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (8/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 10/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.17it/s, loss=2.8618]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.17it/s, loss=2.8618]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.54it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0740, Train Acc: 0.2770\n",
      "  Val Loss: 2.7094, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000003\n",
      "  Train Preds: Class 0=56, Class 1=268, Class 2=102\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (9/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 11/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.26it/s, loss=2.6807]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.26it/s, loss=2.6807]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.29it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9841, Train Acc: 0.3545\n",
      "  Val Loss: 2.7094, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000002\n",
      "  Train Preds: Class 0=51, Class 1=265, Class 2=110\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (10/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 12/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.07it/s, loss=3.2285]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.07it/s, loss=3.2285]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.36it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8899, Train Acc: 0.3169\n",
      "  Val Loss: 2.7094, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000001\n",
      "  Train Preds: Class 0=58, Class 1=285, Class 2=83\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (11/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 13/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.84it/s, loss=3.2266]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.84it/s, loss=3.2266]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.07it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9502, Train Acc: 0.3474\n",
      "  Val Loss: 2.7093, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000001\n",
      "  Train Preds: Class 0=72, Class 1=250, Class 2=104\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (12/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 14/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.06it/s, loss=1.5825]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.06it/s, loss=1.5825]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.10it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8961, Train Acc: 0.3380\n",
      "  Val Loss: 2.7097, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000000\n",
      "  Train Preds: Class 0=63, Class 1=256, Class 2=107\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (13/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 15/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.04it/s, loss=2.3334]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.04it/s, loss=2.3334]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.21it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9743, Train Acc: 0.3122\n",
      "  Val Loss: 2.7094, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=66, Class 1=247, Class 2=113\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (14/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 16/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.80it/s, loss=3.2475]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.80it/s, loss=3.2475]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.68it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0604, Train Acc: 0.3263\n",
      "  Val Loss: 2.7096, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=68, Class 1=264, Class 2=94\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (15/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 17/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=3.9111]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=3.9111]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.40it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0008, Train Acc: 0.3052\n",
      "  Val Loss: 2.7096, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=77, Class 1=238, Class 2=111\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (16/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 18/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.19it/s, loss=2.3790]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.19it/s, loss=2.3790]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.28it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8794, Train Acc: 0.3427\n",
      "  Val Loss: 2.7097, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=82, Class 1=242, Class 2=102\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (17/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 19/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.20it/s, loss=2.7432]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.20it/s, loss=2.7432]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.30it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8920, Train Acc: 0.3263\n",
      "  Val Loss: 2.7098, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=86, Class 1=219, Class 2=121\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (18/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 20/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.08it/s, loss=2.5561]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.08it/s, loss=2.5561]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 16.93it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9113, Train Acc: 0.3216\n",
      "  Val Loss: 2.7099, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=100, Class 1=214, Class 2=112\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (19/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 21/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.81it/s, loss=1.5362]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.81it/s, loss=1.5362]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.38it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9382, Train Acc: 0.3357\n",
      "  Val Loss: 2.7099, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=94, Class 1=213, Class 2=119\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (20/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 22/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:03<00:00, 13.94it/s, loss=2.7772]\n",
      "Training: 100%|██████████| 54/54 [00:03<00:00, 13.94it/s, loss=2.7772]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.37it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8488, Train Acc: 0.3451\n",
      "  Val Loss: 2.7100, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=87, Class 1=199, Class 2=140\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (21/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 23/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.65it/s, loss=2.3238]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.65it/s, loss=2.3238]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.27it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9164, Train Acc: 0.3545\n",
      "  Val Loss: 2.7102, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=92, Class 1=188, Class 2=146\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (22/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 24/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.14it/s, loss=2.3556]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.14it/s, loss=2.3556]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.48it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9222, Train Acc: 0.2958\n",
      "  Val Loss: 2.7101, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=95, Class 1=190, Class 2=141\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (23/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 25/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.21it/s, loss=2.4148]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.21it/s, loss=2.4148]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.40it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9260, Train Acc: 0.3310\n",
      "  Val Loss: 2.7103, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=103, Class 1=189, Class 2=134\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (24/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 26/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.91it/s, loss=3.6230]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.91it/s, loss=3.6230]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.95it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9371, Train Acc: 0.3028\n",
      "  Val Loss: 2.7104, Val Acc: 0.4486, Val F1: 0.2065\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=115, Class 1=171, Class 2=140\n",
      "  Val Preds: Class 0=0, Class 1=107, Class 2=0\n",
      "  Per-class F1: Healthy=0.000, COPD=0.619, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 1!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (25/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 27/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.00it/s, loss=2.4318]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.00it/s, loss=2.4318]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.90it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8752, Train Acc: 0.3333\n",
      "  Val Loss: 2.7106, Val Acc: 0.4206, Val F1: 0.2833\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=109, Class 1=183, Class 2=134\n",
      "  Val Preds: Class 0=0, Class 1=82, Class 2=25\n",
      "  Per-class F1: Healthy=0.000, COPD=0.569, Asthma=0.281\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  💾 Best model saved! (F1: 0.2833, Acc: 0.4206)\n",
      "\n",
      "======================================================================\n",
      "Epoch 28/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.97it/s, loss=2.6652]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.97it/s, loss=2.6652]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.83it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8737, Train Acc: 0.3545\n",
      "  Val Loss: 2.7106, Val Acc: 0.4299, Val F1: 0.2745\n",
      "  Learning Rate: 0.000006\n",
      "  Train Preds: Class 0=122, Class 1=182, Class 2=122\n",
      "  Val Preds: Class 0=0, Class 1=88, Class 2=19\n",
      "  Per-class F1: Healthy=0.000, COPD=0.588, Asthma=0.235\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (1/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 29/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.94it/s, loss=2.4011]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.94it/s, loss=2.4011]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 21.08it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9613, Train Acc: 0.3239\n",
      "  Val Loss: 2.7106, Val Acc: 0.4393, Val F1: 0.2808\n",
      "  Learning Rate: 0.000006\n",
      "  Train Preds: Class 0=102, Class 1=164, Class 2=160\n",
      "  Val Preds: Class 0=0, Class 1=93, Class 2=14\n",
      "  Per-class F1: Healthy=0.000, COPD=0.582, Asthma=0.261\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (2/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 30/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.40it/s, loss=3.3556]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.40it/s, loss=3.3556]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.15it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9739, Train Acc: 0.3122\n",
      "  Val Loss: 2.7107, Val Acc: 0.3645, Val F1: 0.2743\n",
      "  Learning Rate: 0.000005\n",
      "  Train Preds: Class 0=108, Class 1=159, Class 2=159\n",
      "  Val Preds: Class 0=0, Class 1=56, Class 2=51\n",
      "  Per-class F1: Healthy=0.000, COPD=0.462, Asthma=0.361\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (3/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 31/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.44it/s, loss=3.3880]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.44it/s, loss=3.3880]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.32it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9988, Train Acc: 0.3451\n",
      "  Val Loss: 2.7107, Val Acc: 0.3645, Val F1: 0.2674\n",
      "  Learning Rate: 0.000005\n",
      "  Train Preds: Class 0=130, Class 1=133, Class 2=163\n",
      "  Val Preds: Class 0=0, Class 1=65, Class 2=42\n",
      "  Per-class F1: Healthy=0.000, COPD=0.478, Asthma=0.324\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (4/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 32/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.18it/s, loss=3.6570]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.18it/s, loss=3.6570]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.26it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9441, Train Acc: 0.3592\n",
      "  Val Loss: 2.7108, Val Acc: 0.3832, Val F1: 0.2914\n",
      "  Learning Rate: 0.000004\n",
      "  Train Preds: Class 0=116, Class 1=162, Class 2=148\n",
      "  Val Preds: Class 0=0, Class 1=49, Class 2=58\n",
      "  Per-class F1: Healthy=0.000, COPD=0.474, Asthma=0.400\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  💾 Best model saved! (F1: 0.2914, Acc: 0.3832)\n",
      "\n",
      "======================================================================\n",
      "Epoch 33/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.01it/s, loss=2.7485]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.01it/s, loss=2.7485]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 16.15it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0299, Train Acc: 0.3216\n",
      "  Val Loss: 2.7108, Val Acc: 0.3738, Val F1: 0.2846\n",
      "  Learning Rate: 0.000004\n",
      "  Train Preds: Class 0=104, Class 1=155, Class 2=167\n",
      "  Val Preds: Class 0=0, Class 1=48, Class 2=59\n",
      "  Per-class F1: Healthy=0.000, COPD=0.458, Asthma=0.396\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (1/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 34/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.26it/s, loss=2.7485]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.26it/s, loss=2.7485]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.25it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9841, Train Acc: 0.3638\n",
      "  Val Loss: 2.7109, Val Acc: 0.4019, Val F1: 0.3066\n",
      "  Learning Rate: 0.000003\n",
      "  Train Preds: Class 0=127, Class 1=142, Class 2=157\n",
      "  Val Preds: Class 0=0, Class 1=43, Class 2=64\n",
      "  Per-class F1: Healthy=0.000, COPD=0.462, Asthma=0.458\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  💾 Best model saved! (F1: 0.3066, Acc: 0.4019)\n",
      "\n",
      "======================================================================\n",
      "Epoch 35/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.02it/s, loss=4.0184]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.02it/s, loss=4.0184]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.25it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9725, Train Acc: 0.3169\n",
      "  Val Loss: 2.7109, Val Acc: 0.4019, Val F1: 0.3066\n",
      "  Learning Rate: 0.000003\n",
      "  Train Preds: Class 0=116, Class 1=156, Class 2=154\n",
      "  Val Preds: Class 0=0, Class 1=43, Class 2=64\n",
      "  Per-class F1: Healthy=0.000, COPD=0.462, Asthma=0.458\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (1/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 36/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.04it/s, loss=4.0549]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.04it/s, loss=4.0549]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.21it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9561, Train Acc: 0.3099\n",
      "  Val Loss: 2.7108, Val Acc: 0.3925, Val F1: 0.2994\n",
      "  Learning Rate: 0.000002\n",
      "  Train Preds: Class 0=139, Class 1=137, Class 2=150\n",
      "  Val Preds: Class 0=0, Class 1=46, Class 2=61\n",
      "  Per-class F1: Healthy=0.000, COPD=0.468, Asthma=0.430\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (2/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 37/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.00it/s, loss=3.5792]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.00it/s, loss=3.5792]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.53it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9472, Train Acc: 0.3474\n",
      "  Val Loss: 2.7109, Val Acc: 0.3738, Val F1: 0.3593\n",
      "  Learning Rate: 0.000002\n",
      "  Train Preds: Class 0=130, Class 1=132, Class 2=164\n",
      "  Val Preds: Class 0=44, Class 1=40, Class 2=23\n",
      "  Per-class F1: Healthy=0.310, COPD=0.477, Asthma=0.291\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  💾 Best model saved! (F1: 0.3593, Acc: 0.3738)\n",
      "\n",
      "======================================================================\n",
      "Epoch 38/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.01it/s, loss=2.7798]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.01it/s, loss=2.7798]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 22.95it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9042, Train Acc: 0.3521\n",
      "  Val Loss: 2.7109, Val Acc: 0.3925, Val F1: 0.2994\n",
      "  Learning Rate: 0.000001\n",
      "  Train Preds: Class 0=115, Class 1=152, Class 2=159\n",
      "  Val Preds: Class 0=0, Class 1=46, Class 2=61\n",
      "  Per-class F1: Healthy=0.000, COPD=0.468, Asthma=0.430\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (1/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 39/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:03<00:00, 17.96it/s, loss=2.4214]\n",
      "Training: 100%|██████████| 54/54 [00:03<00:00, 17.96it/s, loss=2.4214]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.71it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8839, Train Acc: 0.3427\n",
      "  Val Loss: 2.7108, Val Acc: 0.3551, Val F1: 0.2614\n",
      "  Learning Rate: 0.000001\n",
      "  Train Preds: Class 0=140, Class 1=129, Class 2=157\n",
      "  Val Preds: Class 0=0, Class 1=63, Class 2=44\n",
      "  Per-class F1: Healthy=0.000, COPD=0.468, Asthma=0.316\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (2/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 40/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.35it/s, loss=3.6001]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.35it/s, loss=3.6001]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.28it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0450, Train Acc: 0.3709\n",
      "  Val Loss: 2.7111, Val Acc: 0.3645, Val F1: 0.2681\n",
      "  Learning Rate: 0.000001\n",
      "  Train Preds: Class 0=129, Class 1=128, Class 2=169\n",
      "  Val Preds: Class 0=0, Class 1=22, Class 2=85\n",
      "  Per-class F1: Healthy=0.000, COPD=0.343, Asthma=0.462\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (3/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 41/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.45it/s, loss=3.3407]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.45it/s, loss=3.3407]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.44it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9560, Train Acc: 0.3146\n",
      "  Val Loss: 2.7110, Val Acc: 0.3738, Val F1: 0.2829\n",
      "  Learning Rate: 0.000001\n",
      "  Train Preds: Class 0=128, Class 1=136, Class 2=162\n",
      "  Val Preds: Class 0=0, Class 1=32, Class 2=75\n",
      "  Per-class F1: Healthy=0.000, COPD=0.400, Asthma=0.449\n",
      "  ⚠️  WARNING: Ignoring class 0!\n",
      "  No improvement (4/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 42/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.27it/s, loss=2.6538]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.27it/s, loss=2.6538]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.52it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0163, Train Acc: 0.3521\n",
      "  Val Loss: 2.7111, Val Acc: 0.2804, Val F1: 0.2612\n",
      "  Learning Rate: 0.000000\n",
      "  Train Preds: Class 0=125, Class 1=135, Class 2=166\n",
      "  Val Preds: Class 0=71, Class 1=11, Class 2=25\n",
      "  Per-class F1: Healthy=0.367, COPD=0.136, Asthma=0.281\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (5/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 43/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.27it/s, loss=3.6745]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.27it/s, loss=3.6745]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.36it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0276, Train Acc: 0.3075\n",
      "  Val Loss: 2.7110, Val Acc: 0.3364, Val F1: 0.3305\n",
      "  Learning Rate: 0.000000\n",
      "  Train Preds: Class 0=112, Class 1=138, Class 2=176\n",
      "  Val Preds: Class 0=60, Class 1=22, Class 2=25\n",
      "  Per-class F1: Healthy=0.368, COPD=0.343, Asthma=0.281\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (6/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 44/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.21it/s, loss=3.5838]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.21it/s, loss=3.5838]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.79it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9428, Train Acc: 0.3333\n",
      "  Val Loss: 2.7111, Val Acc: 0.3645, Val F1: 0.3258\n",
      "  Learning Rate: 0.000000\n",
      "  Train Preds: Class 0=136, Class 1=138, Class 2=152\n",
      "  Val Preds: Class 0=12, Class 1=20, Class 2=75\n",
      "  Per-class F1: Healthy=0.205, COPD=0.324, Asthma=0.449\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (7/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 45/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.89it/s, loss=2.8247]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.89it/s, loss=2.8247]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.08it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8706, Train Acc: 0.2864\n",
      "  Val Loss: 2.7111, Val Acc: 0.3738, Val F1: 0.3478\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=132, Class 1=130, Class 2=164\n",
      "  Val Preds: Class 0=20, Class 1=20, Class 2=67\n",
      "  Per-class F1: Healthy=0.255, COPD=0.324, Asthma=0.465\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (8/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 46/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.18it/s, loss=3.6056]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.18it/s, loss=3.6056]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.09it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0260, Train Acc: 0.3662\n",
      "  Val Loss: 2.7112, Val Acc: 0.3178, Val F1: 0.2873\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=141, Class 1=134, Class 2=151\n",
      "  Val Preds: Class 0=33, Class 1=10, Class 2=64\n",
      "  Per-class F1: Healthy=0.300, COPD=0.103, Asthma=0.458\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (9/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 47/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.70it/s, loss=1.5996]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.70it/s, loss=1.5996]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.44it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8407, Train Acc: 0.3404\n",
      "  Val Loss: 2.7113, Val Acc: 0.2991, Val F1: 0.2731\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=139, Class 1=129, Class 2=158\n",
      "  Val Preds: Class 0=36, Class 1=10, Class 2=61\n",
      "  Per-class F1: Healthy=0.286, COPD=0.103, Asthma=0.430\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (10/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 48/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.18it/s, loss=3.6203]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.18it/s, loss=3.6203]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.33it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9874, Train Acc: 0.3615\n",
      "  Val Loss: 2.7115, Val Acc: 0.2991, Val F1: 0.2681\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=138, Class 1=117, Class 2=171\n",
      "  Val Preds: Class 0=43, Class 1=4, Class 2=60\n",
      "  Per-class F1: Healthy=0.314, COPD=0.077, Asthma=0.413\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (11/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 49/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.14it/s, loss=2.8389]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.14it/s, loss=2.8389]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.73it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9400, Train Acc: 0.3310\n",
      "  Val Loss: 2.7117, Val Acc: 0.2991, Val F1: 0.2459\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=155, Class 1=116, Class 2=155\n",
      "  Val Preds: Class 0=29, Class 1=3, Class 2=75\n",
      "  Per-class F1: Healthy=0.250, COPD=0.039, Asthma=0.449\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (12/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 50/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=3.5960]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=3.5960]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.07it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9489, Train Acc: 0.3873\n",
      "  Val Loss: 2.7117, Val Acc: 0.2804, Val F1: 0.2468\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=161, Class 1=88, Class 2=177\n",
      "  Val Preds: Class 0=45, Class 1=3, Class 2=59\n",
      "  Per-class F1: Healthy=0.306, COPD=0.039, Asthma=0.396\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (13/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 51/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.12it/s, loss=4.0235]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.12it/s, loss=4.0235]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.17it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8846, Train Acc: 0.3075\n",
      "  Val Loss: 2.7119, Val Acc: 0.2710, Val F1: 0.2286\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=146, Class 1=100, Class 2=180\n",
      "  Val Preds: Class 0=69, Class 1=1, Class 2=37\n",
      "  Per-class F1: Healthy=0.396, COPD=0.000, Asthma=0.290\n",
      "  ✅ GOOD: Predicting all 3 classes!\n",
      "  No improvement (14/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 52/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.07it/s, loss=2.7358]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.07it/s, loss=2.7358]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.12it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9898, Train Acc: 0.3169\n",
      "  Val Loss: 2.7121, Val Acc: 0.2710, Val F1: 0.2272\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=165, Class 1=89, Class 2=172\n",
      "  Val Preds: Class 0=70, Class 1=0, Class 2=37\n",
      "  Per-class F1: Healthy=0.392, COPD=0.000, Asthma=0.290\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (15/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 53/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.91it/s, loss=2.3915]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.91it/s, loss=2.3915]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.84it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8842, Train Acc: 0.3545\n",
      "  Val Loss: 2.7121, Val Acc: 0.2710, Val F1: 0.1880\n",
      "  Learning Rate: 0.000010\n",
      "  Train Preds: Class 0=153, Class 1=94, Class 2=179\n",
      "  Val Preds: Class 0=101, Class 1=0, Class 2=6\n",
      "  Per-class F1: Healthy=0.406, COPD=0.000, Asthma=0.158\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (16/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 54/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.14it/s, loss=2.6515]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 13.14it/s, loss=2.6515]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 21.69it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:00<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9379, Train Acc: 0.3451\n",
      "  Val Loss: 2.7122, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=173, Class 1=84, Class 2=169\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (17/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 55/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.22it/s, loss=2.8019]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.22it/s, loss=2.8019]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.07it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9955, Train Acc: 0.3239\n",
      "  Val Loss: 2.7123, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=174, Class 1=79, Class 2=173\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (18/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 56/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.99it/s, loss=2.5084]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.99it/s, loss=2.5084]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.24it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9846, Train Acc: 0.3028\n",
      "  Val Loss: 2.7126, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=183, Class 1=82, Class 2=161\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (19/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 57/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.29it/s, loss=2.5640]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.29it/s, loss=2.5640]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.17it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9167, Train Acc: 0.3498\n",
      "  Val Loss: 2.7130, Val Acc: 0.2617, Val F1: 0.2182\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=175, Class 1=56, Class 2=195\n",
      "  Val Preds: Class 0=76, Class 1=0, Class 2=31\n",
      "  Per-class F1: Healthy=0.369, COPD=0.000, Asthma=0.286\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (20/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 58/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.48it/s, loss=2.4453]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.48it/s, loss=2.4453]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.22it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 3.0012, Train Acc: 0.3685\n",
      "  Val Loss: 2.7130, Val Acc: 0.2991, Val F1: 0.2290\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=181, Class 1=60, Class 2=185\n",
      "  Val Preds: Class 0=25, Class 1=0, Class 2=82\n",
      "  Per-class F1: Healthy=0.231, COPD=0.000, Asthma=0.456\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (21/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 59/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.13it/s, loss=3.6625]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.13it/s, loss=3.6625]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.94it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8241, Train Acc: 0.2887\n",
      "  Val Loss: 2.7129, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=172, Class 1=67, Class 2=187\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (22/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 60/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.07it/s, loss=3.1422]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.07it/s, loss=3.1422]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.34it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8367, Train Acc: 0.3146\n",
      "  Val Loss: 2.7132, Val Acc: 0.2617, Val F1: 0.2246\n",
      "  Learning Rate: 0.000009\n",
      "  Train Preds: Class 0=173, Class 1=55, Class 2=198\n",
      "  Val Preds: Class 0=59, Class 1=0, Class 2=48\n",
      "  Per-class F1: Healthy=0.349, COPD=0.000, Asthma=0.325\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (23/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 61/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=2.7829]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=2.7829]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.12it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9598, Train Acc: 0.3239\n",
      "  Val Loss: 2.7132, Val Acc: 0.2617, Val F1: 0.2182\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=193, Class 1=42, Class 2=191\n",
      "  Val Preds: Class 0=76, Class 1=0, Class 2=31\n",
      "  Per-class F1: Healthy=0.369, COPD=0.000, Asthma=0.286\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (24/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 62/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:03<00:00, 13.82it/s, loss=2.3457]\n",
      "Training: 100%|██████████| 54/54 [00:03<00:00, 13.82it/s, loss=2.3457]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.94it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9819, Train Acc: 0.3638\n",
      "  Val Loss: 2.7132, Val Acc: 0.2617, Val F1: 0.2179\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=199, Class 1=26, Class 2=201\n",
      "  Val Preds: Class 0=75, Class 1=0, Class 2=32\n",
      "  Per-class F1: Healthy=0.373, COPD=0.000, Asthma=0.281\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (25/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 63/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.21it/s, loss=3.5268]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.21it/s, loss=3.5268]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.41it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9511, Train Acc: 0.3028\n",
      "  Val Loss: 2.7136, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=183, Class 1=39, Class 2=204\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (26/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 64/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.12it/s, loss=3.9666]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.12it/s, loss=3.9666]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.41it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8920, Train Acc: 0.3286\n",
      "  Val Loss: 2.7136, Val Acc: 0.2710, Val F1: 0.2324\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=193, Class 1=34, Class 2=199\n",
      "  Val Preds: Class 0=53, Class 1=0, Class 2=54\n",
      "  Per-class F1: Healthy=0.325, COPD=0.000, Asthma=0.372\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (27/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 65/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.13it/s, loss=3.8961]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.13it/s, loss=3.8961]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.43it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9157, Train Acc: 0.3380\n",
      "  Val Loss: 2.7136, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000008\n",
      "  Train Preds: Class 0=203, Class 1=39, Class 2=184\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (28/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 66/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.13it/s, loss=2.3681]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.13it/s, loss=2.3681]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.45it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9010, Train Acc: 0.3310\n",
      "  Val Loss: 2.7140, Val Acc: 0.3084, Val F1: 0.2544\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=168, Class 1=31, Class 2=227\n",
      "  Val Preds: Class 0=38, Class 1=0, Class 2=69\n",
      "  Per-class F1: Healthy=0.308, COPD=0.000, Asthma=0.455\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (29/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 67/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.51it/s, loss=1.7476]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.51it/s, loss=1.7476]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.90it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.8984, Train Acc: 0.3052\n",
      "  Val Loss: 2.7141, Val Acc: 0.2710, Val F1: 0.1878\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=194, Class 1=37, Class 2=195\n",
      "  Val Preds: Class 0=100, Class 1=0, Class 2=7\n",
      "  Per-class F1: Healthy=0.409, COPD=0.000, Asthma=0.154\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (30/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 68/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.90it/s, loss=3.8925]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 11.90it/s, loss=3.8925]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.31it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9612, Train Acc: 0.3122\n",
      "  Val Loss: 2.7140, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=173, Class 1=39, Class 2=214\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (31/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 69/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.02it/s, loss=2.7540]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.02it/s, loss=2.7540]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.23it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9347, Train Acc: 0.3380\n",
      "  Val Loss: 2.7139, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000007\n",
      "  Train Preds: Class 0=204, Class 1=29, Class 2=193\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (32/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 70/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.06it/s, loss=1.6710]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.06it/s, loss=1.6710]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.26it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9249, Train Acc: 0.3239\n",
      "  Val Loss: 2.7140, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000006\n",
      "  Train Preds: Class 0=190, Class 1=37, Class 2=199\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (33/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 71/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.15it/s, loss=3.8741]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.15it/s, loss=3.8741]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.00it/s]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9285, Train Acc: 0.3122\n",
      "  Val Loss: 2.7142, Val Acc: 0.2523, Val F1: 0.1343\n",
      "  Learning Rate: 0.000006\n",
      "  Train Preds: Class 0=202, Class 1=23, Class 2=201\n",
      "  Val Preds: Class 0=107, Class 1=0, Class 2=0\n",
      "  Per-class F1: Healthy=0.403, COPD=0.000, Asthma=0.000\n",
      "  ⚠️  WARNING: Still predicting only class 0!\n",
      "  → Model may need even stronger regularization\n",
      "  No improvement (34/35)\n",
      "\n",
      "======================================================================\n",
      "Epoch 72/150\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=3.5938]\n",
      "Training: 100%|██████████| 54/54 [00:04<00:00, 12.11it/s, loss=3.5938]\n",
      "Validation: 100%|██████████| 14/14 [00:01<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Results:\n",
      "  Train Loss: 2.9575, Train Acc: 0.2981\n",
      "  Val Loss: 2.7144, Val Acc: 0.2710, Val F1: 0.2127\n",
      "  Learning Rate: 0.000006\n",
      "  Train Preds: Class 0=191, Class 1=29, Class 2=206\n",
      "  Val Preds: Class 0=90, Class 1=0, Class 2=17\n",
      "  Per-class F1: Healthy=0.393, COPD=0.000, Asthma=0.245\n",
      "  ⚠️  WARNING: Ignoring class 1!\n",
      "  No improvement (35/35)\n",
      "\n",
      "⏹️  Early stopping after 72 epochs\n",
      "\n",
      "======================================================================\n",
      "✅ EMERGENCY TRAINING COMPLETE\n",
      "======================================================================\n",
      "Best F1: 0.3593\n",
      "Best Accuracy: 0.3738\n",
      "Best Loss: 2.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EMERGENCY TRAINING MODE - ANTI-COLLAPSE CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use emergency variables\n",
    "model = emergency_model\n",
    "criterion = emergency_criterion\n",
    "optimizer = emergency_optimizer\n",
    "scheduler = emergency_scheduler\n",
    "config = emergency_config\n",
    "active_train_loader = emergency_train_loader\n",
    "val_loader = emergency_val_loader\n",
    "\n",
    "# Training history\n",
    "emergency_history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0\n",
    "patience_counter = 0\n",
    "best_f1 = 0\n",
    "\n",
    "print(f\"\\n🔥 Starting EMERGENCY training:\")\n",
    "print(f\"  Model size: {emergency_params:,} parameters\")\n",
    "print(f\"  Dropout: {config.DROPOUT}\")\n",
    "print(f\"  Learning rate: {config.LEARNING_RATE}\")\n",
    "print(f\"  Batch size: {config.BATCH_SIZE}\")\n",
    "print(f\"  Focal gamma: 5.0\")\n",
    "print(f\"  Class weights: TRIPLED\")\n",
    "print(f\"\\nThis should prevent class collapse!\\n\")\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, train_acc, train_pred_dist = train_epoch(\n",
    "        model, active_train_loader, criterion, optimizer, device, config, \n",
    "        use_mixup=config.USE_AUGMENTATION\n",
    "    )\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_acc, val_preds, val_labels_epoch, val_probs = validate_epoch(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    val_f1 = fbeta_score(val_labels_epoch, val_preds, beta=1, average='macro', zero_division=0)\n",
    "    \n",
    "    # Check validation prediction distribution\n",
    "    unique_preds, pred_counts = np.unique(val_preds, return_counts=True)\n",
    "    val_pred_dist = {int(cls): int(cnt) for cls, cnt in zip(unique_preds, pred_counts)}\n",
    "    \n",
    "    # Per-class metrics\n",
    "    val_f1_per_class = fbeta_score(val_labels_epoch, val_preds, beta=1, average=None, zero_division=0)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    emergency_history['train_loss'].append(train_loss)\n",
    "    emergency_history['train_acc'].append(train_acc)\n",
    "    emergency_history['val_loss'].append(val_loss)\n",
    "    emergency_history['val_acc'].append(val_acc)\n",
    "    emergency_history['learning_rate'].append(current_lr)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n📊 Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"  Train Preds: Class 0={train_pred_dist.get(0,0)}, Class 1={train_pred_dist.get(1,0)}, Class 2={train_pred_dist.get(2,0)}\")\n",
    "    print(f\"  Val Preds: Class 0={val_pred_dist.get(0,0)}, Class 1={val_pred_dist.get(1,0)}, Class 2={val_pred_dist.get(2,0)}\")\n",
    "    print(f\"  Per-class F1: Healthy={val_f1_per_class[0]:.3f}, COPD={val_f1_per_class[1]:.3f}, Asthma={val_f1_per_class[2]:.3f}\")\n",
    "    \n",
    "    # Check for class collapse\n",
    "    num_classes_predicted = len(val_pred_dist)\n",
    "    if num_classes_predicted == 1:\n",
    "        print(f\"  ⚠️  WARNING: Still predicting only class {list(val_pred_dist.keys())[0]}!\")\n",
    "        print(f\"  → Model may need even stronger regularization\")\n",
    "    elif num_classes_predicted == 2:\n",
    "        missing_class = (set([0,1,2]) - set(val_pred_dist.keys())).pop()\n",
    "        print(f\"  ⚠️  WARNING: Ignoring class {missing_class}!\")\n",
    "    else:\n",
    "        print(f\"  ✅ GOOD: Predicting all 3 classes!\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "            'config': config,\n",
    "        }, config.MODEL_DIR / 'emergency_best_model.pth')\n",
    "        \n",
    "        print(f\"  💾 Best model saved! (F1: {val_f1:.4f}, Acc: {val_acc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  No improvement ({patience_counter}/{config.PATIENCE})\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config.PATIENCE:\n",
    "        print(f\"\\n⏹️  Early stopping after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ EMERGENCY TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best F1: {best_f1:.4f}\")\n",
    "print(f\"Best Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Update history for plotting\n",
    "history = emergency_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4158b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING RESPIRATORY DISEASE CLASSIFICATION MODEL\n",
      "USING UNIDIRECTIONAL LSTM WITH ANTI-COLLAPSE STRATEGIES\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     config_to_use = \u001b[43mconfig\u001b[49m\n\u001b[32m     17\u001b[39m     train_loader_to_use = train_loader_balanced \u001b[38;5;28;01mif\u001b[39;00m USE_BALANCED_SAMPLER \u001b[38;5;28;01melse\u001b[39;00m train_loader\n",
      "\u001b[31mNameError\u001b[39m: name 'config' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m         val_loader_to_use = val_loader\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     config_to_use = \u001b[43mconfig\u001b[49m\n\u001b[32m     21\u001b[39m     train_loader_to_use = train_loader_balanced \u001b[38;5;28;01mif\u001b[39;00m USE_BALANCED_SAMPLER \u001b[38;5;28;01melse\u001b[39;00m train_loader\n\u001b[32m     22\u001b[39m     val_loader_to_use = val_loader\n",
      "\u001b[31mNameError\u001b[39m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING RESPIRATORY DISEASE CLASSIFICATION MODEL\")\n",
    "print(\"USING UNIDIRECTIONAL LSTM WITH ANTI-COLLAPSE STRATEGIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# IMPORTANT: Check if we should use emergency config or regular config\n",
    "# If emergency config was created, we need to use emergency datasets/loaders\n",
    "try:\n",
    "    if 'emergency_config' in locals() or 'emergency_config' in globals():\n",
    "        print(\"\\n⚠️  Emergency config detected - using emergency setup\")\n",
    "        print(\"If you want to use the regular config, restart the kernel and skip emergency cells\")\n",
    "        config_to_use = emergency_config\n",
    "        train_loader_to_use = emergency_train_loader\n",
    "        val_loader_to_use = emergency_val_loader\n",
    "    else:\n",
    "        config_to_use = config\n",
    "        train_loader_to_use = train_loader_balanced if USE_BALANCED_SAMPLER else train_loader\n",
    "        val_loader_to_use = val_loader\n",
    "except NameError:\n",
    "    config_to_use = config\n",
    "    train_loader_to_use = train_loader_balanced if USE_BALANCED_SAMPLER else train_loader\n",
    "    val_loader_to_use = val_loader\n",
    "\n",
    "# 🔧 FIX: Detect actual feature size from data loader\n",
    "print(\"\\n🔧 Detecting actual feature size from data...\")\n",
    "sample_batch = next(iter(train_loader_to_use))\n",
    "sample_audio = sample_batch[0]\n",
    "actual_feature_size = sample_audio.shape[2]\n",
    "print(f\"✓ Data provides {actual_feature_size} features\")\n",
    "\n",
    "# Update config to match actual data\n",
    "if actual_feature_size == config_to_use.INPUT_SIZE * 2:\n",
    "    print(f\"✓ Data is concatenated (cough + vowel)\")\n",
    "    config_to_use.COMBINE_MODE = \"concat\"\n",
    "elif actual_feature_size == config_to_use.INPUT_SIZE:\n",
    "    print(f\"✓ Data is averaged or single-source\")\n",
    "    # Keep existing COMBINE_MODE\n",
    "else:\n",
    "    print(f\"⚠️ Unexpected feature size: {actual_feature_size}\")\n",
    "\n",
    "# Reinitialize model with proper weights and correct config\n",
    "print(f\"\\nReinitializing model with balanced weights...\")\n",
    "print(f\"Config being used:\")\n",
    "print(f\"  COMBINE_MODE: {config_to_use.COMBINE_MODE}\")\n",
    "print(f\"  HIDDEN_SIZE: {config_to_use.HIDDEN_SIZE}\")\n",
    "print(f\"  DROPOUT: {config_to_use.DROPOUT}\")\n",
    "print(f\"  LEARNING_RATE: {config_to_use.LEARNING_RATE}\")\n",
    "print(f\"  Expected input features: {config_to_use.INPUT_SIZE * 2 if config_to_use.COMBINE_MODE == 'concat' else config_to_use.INPUT_SIZE}\")\n",
    "\n",
    "model = RespiratoryLSTM(config_to_use).to(device)\n",
    "model._init_weights()\n",
    "\n",
    "# Verify model matches data\n",
    "print(f\"\\n✓ Model input layer expects: {model.batch_norm1.num_features} features\")\n",
    "print(f\"✓ Data provides: {actual_feature_size} features\")\n",
    "if model.batch_norm1.num_features == actual_feature_size:\n",
    "    print(f\"✅ Model and data are aligned!\")\n",
    "else:\n",
    "    print(f\"❌ ERROR: Model expects {model.batch_norm1.num_features} but data has {actual_feature_size}\")\n",
    "    raise RuntimeError(f\"Model-data mismatch! Model expects {model.batch_norm1.num_features} features but data has {actual_feature_size}\")\n",
    "\n",
    "# Compute class weights for balanced training\n",
    "class_weights = compute_class_weights(train_labels, method='sqrt')\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Select loss function based on strategy\n",
    "if USE_FOCAL_LOSS:\n",
    "    print(\"\\nUsing Focal Loss (gamma=3.0) with class weights\")\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=3.0, label_smoothing=0.1)\n",
    "else:\n",
    "    print(\"\\nUsing CrossEntropyLoss with sqrt class weights\")\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "\n",
    "# Use the appropriate loaders\n",
    "print(f\"Using {'Balanced Sampler' if 'train_loader_balanced' in dir() or 'train_loader_balanced' in locals() else 'Standard'} training data\")\n",
    "active_train_loader = train_loader_to_use\n",
    "val_loader = val_loader_to_use\n",
    "\n",
    "# Optimizer with learning rate from config\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config_to_use.LEARNING_RATE, weight_decay=config_to_use.WEIGHT_DECAY)\n",
    "\n",
    "# Cosine annealing scheduler - starts high and gradually decreases\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Update config reference for training loop\n",
    "config = config_to_use\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0\n",
    "patience_counter = 0\n",
    "best_f1 = 0\n",
    "\n",
    "print(f\"\\nStarting training for {config.NUM_EPOCHS} epochs...\")\n",
    "print(f\"Using learning rate: {config.LEARNING_RATE}\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✅ All checks passed - ready to train!\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training phase (with mixup if enabled) - USE BALANCED LOADER\n",
    "    train_loss, train_acc, train_pred_dist = train_epoch(\n",
    "        model, active_train_loader, criterion, optimizer, device, config, \n",
    "        use_mixup=config.USE_AUGMENTATION\n",
    "    )\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_acc, val_preds, val_labels_epoch, val_probs = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Calculate F1 score for this epoch\n",
    "    val_f1 = fbeta_score(val_labels_epoch, val_preds, beta=1, average='macro', zero_division=0)\n",
    "    \n",
    "    # Check validation prediction distribution\n",
    "    unique_preds, pred_counts = np.unique(val_preds, return_counts=True)\n",
    "    val_pred_dist = {int(cls): int(cnt) for cls, cnt in zip(unique_preds, pred_counts)}\n",
    "    \n",
    "    # Per-class metrics for monitoring\n",
    "    val_f1_per_class = fbeta_score(val_labels_epoch, val_preds, beta=1, average=None, zero_division=0)\n",
    "    \n",
    "    # Learning rate scheduling (cosine annealing steps each epoch)\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['learning_rate'].append(current_lr)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"  Train Predictions: Class 0={train_pred_dist.get(0,0)}, Class 1={train_pred_dist.get(1,0)}, Class 2={train_pred_dist.get(2,0)}\")\n",
    "    print(f\"  Val Predictions: Class 0={val_pred_dist.get(0,0)}, Class 1={val_pred_dist.get(1,0)}, Class 2={val_pred_dist.get(2,0)}\")\n",
    "    print(f\"  Per-class F1: Healthy={val_f1_per_class[0]:.3f}, COPD={val_f1_per_class[1]:.3f}, Asthma={val_f1_per_class[2]:.3f}\")\n",
    "    \n",
    "    # Check for class collapse (if model predicts only one class)\n",
    "    if len(val_pred_dist) == 1:\n",
    "        print(f\"  ⚠️  WARNING: Model is only predicting class {list(val_pred_dist.keys())[0]}!\")\n",
    "        print(f\"  Suggestion: Increase class weights or use stronger augmentation\")\n",
    "    elif len(val_pred_dist) == 2:\n",
    "        print(f\"  ⚠️  WARNING: Model is ignoring class {set([0,1,2]) - set(val_pred_dist.keys())}!\")\n",
    "    \n",
    "    # Save best model based on F1 score (more robust than accuracy for imbalanced data)\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_val_loss = val_loss\n",
    "        best_val_acc = val_acc\n",
    "        patience_counter = 0\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1,\n",
    "            'config': config,\n",
    "        }, config.MODEL_DIR / 'best_unidirectional_lstm_model.pth')\n",
    "        \n",
    "        print(f\"  ✓ Best model saved! (Val F1: {val_f1:.4f}, Val Acc: {val_acc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  No improvement ({patience_counter}/{config.PATIENCE})\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config.PATIENCE:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Validation F1: {best_f1:.4f}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d95512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIX: Align model input size with actual data dimensions\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\udd27 FIX: Aligning Model with Data Dimensions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get actual feature count from data\n",
    "sample_batch = next(iter(active_train_loader))\n",
    "sample_audio, sample_lengths, sample_labels, sample_ids = sample_batch\n",
    "\n",
    "actual_features = sample_audio.shape[2]\n",
    "print(f\"\\n✓ Detected actual feature count from data: {actual_features}\")\n",
    "\n",
    "# Check what the config says\n",
    "if config.COMBINE_MODE == \"concat\":\n",
    "    expected_features = config.INPUT_SIZE * 2\n",
    "elif config.COMBINE_MODE == \"average\":\n",
    "    expected_features = config.INPUT_SIZE\n",
    "elif config.COMBINE_MODE in [\"cough_only\", \"vowel_only\"]:\n",
    "    expected_features = config.INPUT_SIZE\n",
    "else:\n",
    "    expected_features = config.INPUT_SIZE\n",
    "\n",
    "print(f\"✓ Config says COMBINE_MODE='{config.COMBINE_MODE}'\")\n",
    "print(f\"✓ Config expected features: {expected_features}\")\n",
    "\n",
    "if actual_features != expected_features:\n",
    "    print(f\"\\n⚠️  Mismatch detected! Data has {actual_features} but config expects {expected_features}\")\n",
    "    print(f\"💡 Fixing by updating config to match the actual data...\")\n",
    "    \n",
    "    # Update config to match reality\n",
    "    if actual_features == config.INPUT_SIZE * 2:\n",
    "        config.COMBINE_MODE = \"concat\"\n",
    "        print(f\"   → Changed COMBINE_MODE to 'concat'\")\n",
    "    elif actual_features == config.INPUT_SIZE:\n",
    "        config.COMBINE_MODE = \"average\"  # or could be cough_only/vowel_only\n",
    "        print(f\"   → Changed COMBINE_MODE to 'average'\")\n",
    "    \n",
    "    # Reinitialize model with corrected config\n",
    "    print(f\"\\n\udd04 Reinitializing model with correct input size...\")\n",
    "    model = RespiratoryLSTM(config).to(device)\n",
    "    model._init_weights()\n",
    "    \n",
    "    # Reinitialize optimizer and scheduler for new model\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "    \n",
    "    print(f\"✅ Model reinitialized successfully!\")\n",
    "\n",
    "# Final verification\n",
    "print(f\"\\n✓ Final Verification:\")\n",
    "print(f\"  Model input layer expects: {model.batch_norm1.num_features} features\")\n",
    "print(f\"  Data provides: {actual_features} features\")\n",
    "print(f\"  Match: {'✅ YES' if model.batch_norm1.num_features == actual_features else '❌ NO'}\")\n",
    "\n",
    "print(f\"\\n✓ Model Configuration:\")\n",
    "print(f\"  COMBINE_MODE: {config.COMBINE_MODE}\")\n",
    "print(f\"  INPUT_SIZE: {config.INPUT_SIZE}\")\n",
    "print(f\"  HIDDEN_SIZE: {config.HIDDEN_SIZE}\")\n",
    "print(f\"  DROPOUT: {config.DROPOUT}\")\n",
    "print(f\"  LEARNING_RATE: {config.LEARNING_RATE}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ Ready to train!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094eb79",
   "metadata": {},
   "source": [
    "## 9. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss (Unidirectional LSTM)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy (Unidirectional LSTM)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Learning rate plot\n",
    "axes[2].plot(history['learning_rate'], marker='o', color='green')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Learning Rate')\n",
    "axes[2].set_title('Learning Rate Schedule')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f600b1",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(config.MODEL_DIR / 'best_unidirectional_lstm_model.pth', map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best unidirectional LSTM model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"  Best Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"  Best Val Acc: {checkpoint['val_acc']:.4f}\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc, val_preds, val_labels, val_probs = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "# Calculate detailed metrics\n",
    "val_metrics = evaluate_model(val_labels, val_preds, val_probs, \"Validation Set Performance (Unidirectional LSTM)\")\n",
    "plot_confusion_matrix(val_metrics['confusion_matrix'], \"Confusion Matrix - Validation Set (Unidirectional LSTM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d15c50c",
   "metadata": {},
   "source": [
    "## 11. Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(model, dataloader, device):\n",
    "    \"\"\"Generate predictions for test set\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_candidate_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for audio, lengths, candidate_ids in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            audio = audio.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(audio, lengths)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_candidate_ids.extend(candidate_ids)\n",
    "    \n",
    "    return all_candidate_ids, all_preds, all_probs\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING TEST SET PREDICTIONS (UNIDIRECTIONAL LSTM)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate predictions\n",
    "test_candidate_ids, test_preds, test_probs = predict_test_set(model, test_loader, device)\n",
    "\n",
    "print(f\"\\nGenerated predictions for {len(test_preds)} test samples\")\n",
    "\n",
    "# Create predictions dictionary\n",
    "predictions_dict = {}\n",
    "for cid, pred, prob in zip(test_candidate_ids, test_preds, test_probs):\n",
    "    predictions_dict[cid] = {\n",
    "        'disease': int(pred),\n",
    "        'probs': prob\n",
    "    }\n",
    "\n",
    "# Get all candidates from test_df\n",
    "all_test_candidates = test_df['candidateID'].tolist()\n",
    "print(f\"Total test candidates in test.csv: {len(all_test_candidates)}\")\n",
    "\n",
    "# Check for missing predictions\n",
    "missing_candidates = []\n",
    "for cid in all_test_candidates:\n",
    "    if cid not in predictions_dict:\n",
    "        missing_candidates.append(cid)\n",
    "\n",
    "if missing_candidates:\n",
    "    print(f\"\\n⚠️  WARNING: {len(missing_candidates)} candidates missing predictions!\")\n",
    "    print(f\"First 5 missing: {missing_candidates[:5]}\")\n",
    "    print(f\"Assigning default prediction (class 1 - COPD) to missing candidates...\")\n",
    "    \n",
    "    # Assign default prediction\n",
    "    default_class = 1  # COPD\n",
    "    default_probs = np.array([0.0, 1.0, 0.0])\n",
    "    \n",
    "    for cid in missing_candidates:\n",
    "        predictions_dict[cid] = {\n",
    "            'disease': default_class,\n",
    "            'probs': default_probs\n",
    "        }\n",
    "\n",
    "# Create submission dataframe with ALL candidates in original order\n",
    "submission_df = pd.DataFrame({\n",
    "    'candidateID': all_test_candidates,\n",
    "    'disease': [predictions_dict[cid]['disease'] for cid in all_test_candidates]\n",
    "})\n",
    "\n",
    "# Verify we have the correct number of rows\n",
    "assert len(submission_df) == len(test_df), f\"Submission has {len(submission_df)} rows, expected {len(test_df)}\"\n",
    "print(f\"\\n✓ Submission has correct number of rows: {len(submission_df)}\")\n",
    "\n",
    "# Save predictions in submission format\n",
    "submission_path = config.BASE_PATH / 'submission_unidirectional_lstm.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"✓ Submission file saved to '{submission_path}'\")\n",
    "\n",
    "# Also save detailed predictions with probabilities\n",
    "detailed_df = pd.DataFrame({\n",
    "    'candidateID': all_test_candidates,\n",
    "    'predicted_disease': [predictions_dict[cid]['disease'] for cid in all_test_candidates],\n",
    "    'prob_class_0': [predictions_dict[cid]['probs'][0] for cid in all_test_candidates],\n",
    "    'prob_class_1': [predictions_dict[cid]['probs'][1] for cid in all_test_candidates],\n",
    "    'prob_class_2': [predictions_dict[cid]['probs'][2] for cid in all_test_candidates]\n",
    "})\n",
    "detailed_path = config.BASE_PATH / 'submission_unidirectional_lstm_detailed.csv'\n",
    "detailed_df.to_csv(detailed_path, index=False)\n",
    "print(f\"✓ Detailed predictions saved to '{detailed_path}'\")\n",
    "\n",
    "# Display first few predictions\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Prediction distribution\n",
    "print(\"\\nPrediction distribution:\")\n",
    "pred_counts = submission_df['disease'].value_counts().sort_index()\n",
    "class_names = ['Healthy', 'COPD', 'Asthma']\n",
    "for cls, cnt in pred_counts.items():\n",
    "    print(f\"  Class {cls} ({class_names[int(cls)]}): {cnt} ({cnt/len(submission_df)*100:.1f}%)\")\n",
    "\n",
    "if missing_candidates:\n",
    "    print(f\"\\nNote: {len(missing_candidates)} candidates received default predictions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e76db",
   "metadata": {},
   "source": [
    "## 12. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY - UNIDIRECTIONAL LSTM MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. MODEL ARCHITECTURE\")\n",
    "print(f\"   Type: Unidirectional LSTM with Attention Mechanism\")\n",
    "print(f\"   Input Size: {config.INPUT_SIZE * 2 if config.COMBINE_MODE == 'concat' else config.INPUT_SIZE}\")\n",
    "print(f\"   Hidden Size: {config.HIDDEN_SIZE}\")\n",
    "print(f\"   Layers: {config.NUM_LAYERS}\")\n",
    "print(f\"   Bidirectional: {config.BIDIRECTIONAL} *** UNIDIRECTIONAL ***\")\n",
    "print(f\"   Dropout: {config.DROPOUT}\")\n",
    "print(f\"   Total Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\n2. TRAINING CONFIGURATION\")\n",
    "print(f\"   Combine Mode: {config.COMBINE_MODE}\")\n",
    "print(f\"   Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"   Learning Rate: {config.LEARNING_RATE}\")\n",
    "print(f\"   Weight Decay: {config.WEIGHT_DECAY}\")\n",
    "print(f\"   Gradient Clip: {config.GRADIENT_CLIP}\")\n",
    "print(f\"   Class Weighting: sqrt method\")\n",
    "\n",
    "print(\"\\n3. DATASET\")\n",
    "print(f\"   Training: {len(train_dataset)} samples\")\n",
    "print(f\"   Validation: {len(val_dataset)} samples\")\n",
    "print(f\"   Test: {len(test_dataset)} samples\")\n",
    "\n",
    "print(\"\\n4. PERFORMANCE METRICS (Validation Set)\")\n",
    "print(f\"   Accuracy:  {val_metrics['accuracy']:.4f}\")\n",
    "print(f\"   Precision: {val_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall:    {val_metrics['recall']:.4f}\")\n",
    "print(f\"   F1 Score:  {val_metrics['f1_score']:.4f}\")\n",
    "print(f\"   F2 Score:  {val_metrics['f2_score']:.4f}\")\n",
    "\n",
    "print(\"\\n5. OUTPUT FILES\")\n",
    "print(f\"   Model: {config.MODEL_DIR / 'best_unidirectional_lstm_model.pth'}\")\n",
    "print(f\"   Submission: {submission_path}\")\n",
    "print(f\"   Detailed: {detailed_path}\")\n",
    "\n",
    "print(\"\\n6. CLASS LABELS\")\n",
    "print(f\"   0: Healthy\")\n",
    "print(f\"   1: COPD\")\n",
    "print(f\"   2: Asthma\")\n",
    "\n",
    "print(\"\\n7. MODEL COMPARISON\")\n",
    "print(f\"   This model uses UNIDIRECTIONAL LSTM\")\n",
    "print(f\"   - Processes sequences in forward direction only\")\n",
    "print(f\"   - Faster training and inference\")\n",
    "print(f\"   - Fewer parameters compared to bidirectional\")\n",
    "print(f\"   - May be more suitable for time-series data where future context is not needed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-torch (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
