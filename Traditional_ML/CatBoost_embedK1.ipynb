{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f632fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7923b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cough specialist samples: 515 (missing: 29)\n",
      "Vowel specialist samples: 540 (missing: 4)\n",
      "\n",
      "Cough specialist validation metrics (holdout 20%):\n",
      "  f1_macro: 0.3731\n",
      "  accuracy: 0.4660\n",
      "  precision_macro: 0.3854\n",
      "  recall_macro: 0.3953\n",
      "\n",
      "Vowel specialist validation metrics (holdout 20%):\n",
      "  f1_macro: 0.4850\n",
      "  accuracy: 0.5556\n",
      "  precision_macro: 0.6329\n",
      "  recall_macro: 0.4977\n",
      "Saved submission to submission_CatBoost_dual_audio.csv with 338 rows\n",
      "Prediction source counts:\n",
      " vowel    194\n",
      "cough    144\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "ROOT = Path('.')\n",
    "TRAIN_CSV = ROOT / 'train_air_respiratory.csv'\n",
    "TEST_CSV = ROOT / 'test_air_respiratory.csv'\n",
    "SOUNDS_DIR = ROOT / 'sounds'\n",
    "\n",
    "def load_mean_embedding(json_path: Path):\n",
    "    if not json_path.exists():\n",
    "        return None\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    arr = np.asarray(data, dtype=np.float32)\n",
    "    if arr.ndim == 2:\n",
    "        emb = arr.mean(axis=0)\n",
    "    elif arr.ndim == 1:\n",
    "        emb = arr\n",
    "    else:\n",
    "        return None\n",
    "    return emb if emb.shape[0] == 512 else None\n",
    "\n",
    "# Load and deduplicate train labels (one row per candidateID)\n",
    "train_df = pd.read_csv(TRAIN_CSV).drop_duplicates(subset=['candidateID'])\n",
    "label_map = dict(zip(train_df['candidateID'], train_df['disease']))\n",
    "\n",
    "# Build specialist datasets\n",
    "cough_X, cough_y, vowel_X, vowel_y = [], [], [], []\n",
    "missing_cough, missing_vowel = 0, 0\n",
    "\n",
    "for cid, label in label_map.items():\n",
    "    base = SOUNDS_DIR / cid\n",
    "    cough_emb = load_mean_embedding(base / 'emb_cough.json')\n",
    "    if cough_emb is not None:\n",
    "        cough_X.append(cough_emb)\n",
    "        cough_y.append(label)\n",
    "    else:\n",
    "        missing_cough += 1\n",
    "\n",
    "    vowel_emb = load_mean_embedding(base / 'emb_vowel.json')\n",
    "    if vowel_emb is not None:\n",
    "        vowel_X.append(vowel_emb)\n",
    "        vowel_y.append(label)\n",
    "    else:\n",
    "        missing_vowel += 1\n",
    "\n",
    "cough_X = np.vstack(cough_X) if cough_X else np.empty((0, 512))\n",
    "vowel_X = np.vstack(vowel_X) if vowel_X else np.empty((0, 512))\n",
    "cough_y = np.array(cough_y)\n",
    "vowel_y = np.array(vowel_y)\n",
    "\n",
    "print(f\"Cough specialist samples: {len(cough_y)} (missing: {missing_cough})\")\n",
    "print(f\"Vowel specialist samples: {len(vowel_y)} (missing: {missing_vowel})\")\n",
    "\n",
    "# Train specialists (audio-only) with optional holdout metrics\n",
    "base_params = dict(\n",
    "    depth=6,                    \n",
    "    learning_rate=0.1,\n",
    "    iterations=400,             \n",
    "    subsample=0.9,\n",
    "    bootstrap_type='Bernoulli',\n",
    "    rsm=0.9,                    \n",
    "    loss_function='MultiClass', \n",
    "    classes_count=3,           \n",
    "    thread_count=4,             \n",
    "    random_seed=42,\n",
    "    verbose=0,                 \n",
    "    allow_writing_files=False  \n",
    "     )\n",
    "\n",
    "\n",
    "def train_with_eval(X, y, name: str):\n",
    "    if len(y) == 0:\n",
    "        print(f\"{name}: no data, training skipped\")\n",
    "        return None\n",
    "\n",
    "    unique_classes = np.unique(y)\n",
    "    can_eval = len(y) >= 10 and len(unique_classes) >= 2\n",
    "    if can_eval:\n",
    "        stratify = y if len(unique_classes) > 1 else None\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=stratify\n",
    "        )\n",
    "        model = CatBoostClassifier(**base_params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        val_pred = model.predict(X_val)\n",
    "        metrics = {\n",
    "            'f1_macro': f1_score(y_val, val_pred, average='macro'),\n",
    "            'accuracy': accuracy_score(y_val, val_pred),\n",
    "            'precision_macro': precision_score(y_val, val_pred, average='macro', zero_division=0),\n",
    "            'recall_macro': recall_score(y_val, val_pred, average='macro'),\n",
    "        }\n",
    "        print(f\"\\n{name} validation metrics (holdout 20%):\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{name}: skipped holdout metrics (samples={len(y)}, classes={len(unique_classes)})\")\n",
    "\n",
    "    # Refit on full data for final model\n",
    "    final_model = CatBoostClassifier(**base_params)\n",
    "    final_model.fit(X, y)\n",
    "    return final_model\n",
    "\n",
    "\n",
    "cough_model = train_with_eval(cough_X, cough_y, \"Cough specialist\")\n",
    "vowel_model = train_with_eval(vowel_X, vowel_y, \"Vowel specialist\")\n",
    "\n",
    "# Inference judge\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "preds, sources = [], []\n",
    "\n",
    "for cid in test_df['candidateID']:\n",
    "    base = SOUNDS_DIR / cid\n",
    "    options = []\n",
    "\n",
    "    cough_emb = load_mean_embedding(base / 'emb_cough.json')\n",
    "    if cough_emb is not None and cough_model is not None:\n",
    "        prob = cough_model.predict_proba(cough_emb.reshape(1, -1))[0]\n",
    "        options.append((prob, 'cough'))\n",
    "\n",
    "    vowel_emb = load_mean_embedding(base / 'emb_vowel.json')\n",
    "    if vowel_emb is not None and vowel_model is not None:\n",
    "        prob = vowel_model.predict_proba(vowel_emb.reshape(1, -1))[0]\n",
    "        options.append((prob, 'vowel'))\n",
    "\n",
    "    if options:\n",
    "        best_prob, best_src = max(options, key=lambda item: item[0].max())\n",
    "        pred_class = int(best_prob.argmax())\n",
    "    else:\n",
    "        best_src = 'fallback'\n",
    "        pred_class = 2  # hardcoded fallback\n",
    "\n",
    "    preds.append(pred_class)\n",
    "    sources.append(best_src)\n",
    "\n",
    "submission = pd.DataFrame({'candidateID': test_df['candidateID'], 'disease': preds})\n",
    "submission_path = ROOT / 'submission_CatBoost_dual_audio.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Saved submission to {submission_path} with {len(submission)} rows\")\n",
    "print(\"Prediction source counts:\\n\", pd.Series(sources).value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
