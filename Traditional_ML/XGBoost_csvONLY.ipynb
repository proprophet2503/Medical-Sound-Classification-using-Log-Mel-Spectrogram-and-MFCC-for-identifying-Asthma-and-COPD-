{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ba0ba7",
   "metadata": {},
   "source": [
    "## Standalone Tabular-Only Pipeline\n",
    "Train XGBoost using only demographic and medical features from CSV. No audio embeddings used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067dcac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TABULAR-ONLY XGBOOST PIPELINE\n",
      "============================================================\n",
      "\n",
      "Train CSV shape: (546, 11)\n",
      "Columns: ['candidateID', 'age', 'gender', 'tbContactHistory', 'wheezingHistory', 'phlegmCough', 'familyAsthmaHistory', 'feverHistory', 'coldPresent', 'packYears', 'disease']\n",
      "After deduplication: 544 unique candidates\n",
      "Target distribution:\n",
      "0    139\n",
      "1    237\n",
      "2    168\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature columns (9): ['age', 'gender', 'tbContactHistory', 'wheezingHistory', 'phlegmCough', 'familyAsthmaHistory', 'feverHistory', 'coldPresent', 'packYears']\n",
      "\n",
      "X_train shape before preprocessing: (544, 9)\n",
      "X_train data types:\n",
      "age                      int64\n",
      "gender                   int64\n",
      "tbContactHistory       float64\n",
      "wheezingHistory        float64\n",
      "phlegmCough            float64\n",
      "familyAsthmaHistory    float64\n",
      "feverHistory             int64\n",
      "coldPresent            float64\n",
      "packYears                int64\n",
      "dtype: object\n",
      "\n",
      "Missing values before imputation:\n",
      "age                      0\n",
      "gender                   0\n",
      "tbContactHistory         0\n",
      "wheezingHistory          0\n",
      "phlegmCough              0\n",
      "familyAsthmaHistory      0\n",
      "feverHistory             0\n",
      "coldPresent            146\n",
      "packYears                0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after imputation:\n",
      "0 total\n",
      "X_train shape after preprocessing: (544, 9)\n",
      "\n",
      "Validation metrics (holdout 20%):\n",
      "  f1_macro: 0.7219\n",
      "  accuracy: 0.7248\n",
      "  precision_macro: 0.7228\n",
      "  recall_macro: 0.7216\n",
      "\n",
      "Validation metrics (holdout 20%):\n",
      "  f1_macro: 0.7219\n",
      "  accuracy: 0.7248\n",
      "  precision_macro: 0.7228\n",
      "  recall_macro: 0.7216\n",
      "\n",
      "Tabular model trained on full dataset.\n",
      "\n",
      "Test CSV shape: (338, 10)\n",
      "X_test shape after preprocessing: (338, 9)\n",
      "\n",
      "Saved tabular-only submission to submission_tabular_only.csv\n",
      "Total rows: 338\n",
      "Prediction distribution:\n",
      "0    112\n",
      "1     96\n",
      "2    130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "TABULAR-ONLY PIPELINE COMPLETED\n",
      "============================================================\n",
      "\n",
      "Tabular model trained on full dataset.\n",
      "\n",
      "Test CSV shape: (338, 10)\n",
      "X_test shape after preprocessing: (338, 9)\n",
      "\n",
      "Saved tabular-only submission to submission_tabular_only.csv\n",
      "Total rows: 338\n",
      "Prediction distribution:\n",
      "0    112\n",
      "1     96\n",
      "2    130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "TABULAR-ONLY PIPELINE COMPLETED\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === STANDALONE TABULAR-ONLY PIPELINE ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Paths\n",
    "ROOT = Path('.')\n",
    "TRAIN_CSV = ROOT / 'train_air_respiratory.csv'\n",
    "TEST_CSV = ROOT / 'test_air_respiratory.csv'\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TABULAR-ONLY XGBOOST PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# === LOAD AND PREPARE TRAINING DATA ===\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "print(f\"\\nTrain CSV shape: {train_df.shape}\")\n",
    "print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "\n",
    "# Remove duplicates by candidateID (keep first occurrence for each ID)\n",
    "train_df = train_df.drop_duplicates(subset=['candidateID'], keep='first')\n",
    "print(f\"After deduplication: {train_df.shape[0]} unique candidates\")\n",
    "\n",
    "# Extract target\n",
    "y_train = train_df['disease'].values\n",
    "print(f\"Target distribution:\\n{pd.Series(y_train).value_counts().sort_index()}\")\n",
    "\n",
    "# Extract features: all columns except candidateID and disease\n",
    "feature_cols = [col for col in train_df.columns if col not in ['candidateID', 'disease']]\n",
    "print(f\"\\nFeature columns ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "print(f\"\\nX_train shape before preprocessing: {X_train.shape}\")\n",
    "print(f\"X_train data types:\\n{X_train.dtypes}\")\n",
    "print(f\"\\nMissing values before imputation:\\n{X_train.isnull().sum()}\")\n",
    "\n",
    "# === PREPROCESSING ===\n",
    "\n",
    "# Create imputer for missing values (most frequent strategy for categorical, median for numeric)\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=feature_cols)\n",
    "\n",
    "print(f\"\\nMissing values after imputation:\\n{X_train_imputed.isnull().sum().sum()} total\")\n",
    "\n",
    "# Convert all to numeric (ensure float dtype for XGBoost)\n",
    "X_train_imputed = X_train_imputed.astype(np.float32)\n",
    "\n",
    "print(f\"X_train shape after preprocessing: {X_train_imputed.shape}\")\n",
    "\n",
    "# === TRAINING WITH VALIDATION ===\n",
    "\n",
    "unique_classes = np.unique(y_train)\n",
    "can_eval = len(y_train) >= 10 and len(unique_classes) >= 2\n",
    "\n",
    "if can_eval:\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train_imputed, y_train, test_size=0.2, random_state=42,\n",
    "        stratify=y_train if len(unique_classes) > 1 else None\n",
    "    )\n",
    "    \n",
    "    xgb_params = dict(\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=400,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        num_class=3,\n",
    "        n_jobs=4,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    tabular_model = xgb.XGBClassifier(**xgb_params)\n",
    "    tabular_model.fit(X_tr, y_tr)\n",
    "    val_pred = tabular_model.predict(X_val)\n",
    "    \n",
    "    print(\"\\nValidation metrics (holdout 20%):\")\n",
    "    print(f\"  f1_macro: {f1_score(y_val, val_pred, average='macro'):.4f}\")\n",
    "    print(f\"  accuracy: {accuracy_score(y_val, val_pred):.4f}\")\n",
    "    print(f\"  precision_macro: {precision_score(y_val, val_pred, average='macro', zero_division=0):.4f}\")\n",
    "    print(f\"  recall_macro: {recall_score(y_val, val_pred, average='macro'):.4f}\")\n",
    "else:\n",
    "    print(\"Tabular: skipped holdout metrics (insufficient samples/classes)\")\n",
    "\n",
    "# Refit on full training data\n",
    "tabular_model = xgb.XGBClassifier(**xgb_params)\n",
    "tabular_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "print(\"\\nTabular model trained on full dataset.\")\n",
    "\n",
    "# === INFERENCE ON TEST SET ===\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "print(f\"\\nTest CSV shape: {test_df.shape}\")\n",
    "\n",
    "# Apply same preprocessing to test set\n",
    "X_test = test_df[feature_cols].copy()\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=feature_cols)\n",
    "X_test_imputed = X_test_imputed.astype(np.float32)\n",
    "\n",
    "print(f\"X_test shape after preprocessing: {X_test_imputed.shape}\")\n",
    "\n",
    "# Generate predictions\n",
    "test_preds = tabular_model.predict(X_test_imputed)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'candidateID': test_df['candidateID'],\n",
    "    'disease': test_preds\n",
    "})\n",
    "\n",
    "submission_path = ROOT / 'submission_Xgb_tabular_only.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved tabular-only submission to {submission_path}\")\n",
    "print(f\"Total rows: {len(submission)}\")\n",
    "print(f\"Prediction distribution:\\n{pd.Series(test_preds).value_counts().sort_index()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TABULAR-ONLY PIPELINE COMPLETED\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
